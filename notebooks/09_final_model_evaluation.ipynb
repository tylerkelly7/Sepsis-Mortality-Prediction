{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12193895",
   "metadata": {},
   "source": [
    "# 9 Final Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb6efb96-44a6-47f5-a3ea-b66710b0925f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import joblib\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import warnings\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "from IPython.display import Image, display;\n",
    "\n",
    "from src.utils import resolve_path, load_latest_artifact\n",
    "from src.evaluation import (\n",
    "    export_summary,\n",
    "    unwrap_best_estimators_non_smote,\n",
    "    unwrap_best_estimators_smote,\n",
    "    plot_roc_across_datasets,\n",
    "    plot_pr,\n",
    "    plot_roc_curves,\n",
    "    plot_delta_auroc_bar,\n",
    "    plot_bar_comparison,\n",
    "    plot_shap_summary,\n",
    "    plot_shap_dependence,\n",
    ")\n",
    "\n",
    "from src.models import get_classifiers\n",
    "classifiers = get_classifiers()\n",
    "\n",
    "\n",
    "# Global settings\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"talk\")\n",
    "plt.rcParams[\"figure.dpi\"] = 120\n",
    "warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"The NumPy global RNG was seeded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6584e803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thesis_ModelTraining\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow.set_tracking_uri(resolve_path(\"mlflow_tracking\"))\n",
    "exp = mlflow.get_experiment(\"169692831354922862\")\n",
    "print(exp.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd3f76f3-063c-4c75-a79b-912885b6a3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ MLflow evaluation run started under experiment 'Thesis_ModelTraining'\n",
      "üíæ Saved and logged merged model comparison summary to C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\results\\evaluation\\opt_model_comparison_summary.csv\n",
      "üìä Logged Non-SMOTE comparison bar plot to MLflow and saved to C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\results\\plots\\w2v_optimized_radiology\\holdout_auroc_comparison_non_smote.png\n",
      "üìä Logged Non-SMOTE comparison bar plot to MLflow and saved to C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\results\\plots\\w2v_optimized_radiology\\holdout_auroc_comparison_non_smote.png\n",
      "üìä Logged SMOTE comparison bar plot to MLflow and saved to C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\results\\plots\\w2v_optimized_radiology\\holdout_auroc_comparison_smote.png\n",
      "üìä Logged SMOTE comparison bar plot to MLflow and saved to C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\results\\plots\\w2v_optimized_radiology\\holdout_auroc_comparison_smote.png\n",
      "‚úÖ Summary exported to C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\results\\evaluation\\20251217\\final_model_summary_20251217_summary.csv\n",
      "Logged ŒîAUROC (optimized vs original) = 0.0408\n",
      "Logged ŒîAUROC (optimized vs w2v baseline) = 0.0259\n",
      "\n",
      "üì¶ Loading all baseline and optimized W2V models for evaluation and interpretation\n",
      "üìÇ Using latest run folder for original_baseline ‚Üí original_baseline_20251027_0818\n",
      "‚è≠Ô∏è  Skipping best model file: original_baseline_20251027_0818_best_model.pkl\n",
      "‚è≠Ô∏è  Skipping best model file: original_baseline_20251027_0818_best_smote_model.pkl\n",
      "‚úÖ Loaded CatBoost           | Baseline\n",
      "‚úÖ Loaded CatBoost           | SMOTE\n",
      "‚úÖ Loaded DecisionTree       | Baseline\n",
      "‚úÖ Loaded DecisionTree       | SMOTE\n",
      "‚úÖ Loaded GradientBoosting   | Baseline\n",
      "‚úÖ Loaded GradientBoosting   | SMOTE\n",
      "‚úÖ Loaded LGBM               | Baseline\n",
      "‚úÖ Loaded LGBM               | SMOTE\n",
      "‚úÖ Loaded LogisticRegression | Baseline\n",
      "‚úÖ Loaded LogisticRegression | SMOTE\n",
      "‚úÖ Loaded MLP                | Baseline\n",
      "‚úÖ Loaded MLP                | SMOTE\n",
      "‚úÖ Loaded NaiveBayes         | Baseline\n",
      "‚úÖ Loaded NaiveBayes         | SMOTE\n",
      "‚úÖ Loaded RandomForest       | Baseline\n",
      "‚úÖ Loaded RandomForest       | SMOTE\n",
      "‚úÖ Loaded SVC                | Baseline\n",
      "‚úÖ Loaded SVC                | SMOTE\n",
      "‚úÖ Loaded XGB                | Baseline\n",
      "‚úÖ Loaded XGB                | SMOTE\n",
      "üìÇ Using latest run folder for w2v_radiology_baseline ‚Üí w2v_radiology_baseline_20251026_1338\n",
      "‚è≠Ô∏è  Skipping best model file: w2v_radiology_baseline_20251026_1338_best_model.pkl\n",
      "‚è≠Ô∏è  Skipping best model file: w2v_radiology_baseline_20251026_1338_best_smote_model.pkl\n",
      "‚úÖ Loaded CatBoost           | Baseline\n",
      "‚úÖ Loaded CatBoost           | SMOTE\n",
      "‚úÖ Loaded DecisionTree       | Baseline\n",
      "‚úÖ Loaded DecisionTree       | SMOTE\n",
      "‚úÖ Loaded GradientBoosting   | Baseline\n",
      "‚úÖ Loaded GradientBoosting   | SMOTE\n",
      "‚úÖ Loaded LGBM               | Baseline\n",
      "‚úÖ Loaded LGBM               | SMOTE\n",
      "‚úÖ Loaded LogisticRegression | Baseline\n",
      "‚úÖ Loaded LogisticRegression | SMOTE\n",
      "‚úÖ Loaded MLP                | Baseline\n",
      "‚úÖ Loaded MLP                | SMOTE\n",
      "‚úÖ Loaded NaiveBayes         | Baseline\n",
      "‚úÖ Loaded NaiveBayes         | SMOTE\n",
      "‚úÖ Loaded RandomForest       | Baseline\n",
      "‚úÖ Loaded RandomForest       | SMOTE\n",
      "‚úÖ Loaded SVC                | Baseline\n",
      "‚úÖ Loaded SVC                | SMOTE\n",
      "‚úÖ Loaded XGB                | Baseline\n",
      "‚úÖ Loaded XGB                | SMOTE\n",
      "üìÇ Using latest run folder for w2v_optimized_radiology ‚Üí w2v_optimized_radiology_20251027_2357\n",
      "‚è≠Ô∏è  Skipping best model file: w2v_optimized_radiology_20251027_2357_best_model.pkl\n",
      "‚è≠Ô∏è  Skipping best model file: w2v_optimized_radiology_20251027_2357_best_smote_model.pkl\n",
      "‚úÖ Loaded CatBoost           | Baseline\n",
      "‚úÖ Loaded CatBoost           | SMOTE\n",
      "‚úÖ Loaded GradientBoosting   | Baseline\n",
      "‚úÖ Loaded GradientBoosting   | SMOTE\n",
      "‚úÖ Loaded LGBM               | Baseline\n",
      "‚úÖ Loaded LGBM               | SMOTE\n",
      "‚úÖ Loaded LogisticRegression | Baseline\n",
      "‚úÖ Loaded LogisticRegression | SMOTE\n",
      "‚úÖ Loaded RandomForest       | Baseline\n",
      "‚úÖ Loaded RandomForest       | SMOTE\n",
      "‚úÖ Loaded XGB                | Baseline\n",
      "‚úÖ Loaded XGB                | SMOTE\n",
      "\n",
      "üìä Summary of loaded models\n",
      "Baseline models ‚Üí 26\n",
      "SMOTE models    ‚Üí 26\n",
      "Baseline keys: ['original_baseline_CatBoost', 'original_baseline_DecisionTree', 'original_baseline_GradientBoosting', 'original_baseline_LGBM', 'original_baseline_LogisticRegression', 'original_baseline_MLP', 'original_baseline_NaiveBayes', 'original_baseline_RandomForest', 'original_baseline_SVC', 'original_baseline_XGB', 'w2v_radiology_baseline_CatBoost', 'w2v_radiology_baseline_DecisionTree', 'w2v_radiology_baseline_GradientBoosting', 'w2v_radiology_baseline_LGBM', 'w2v_radiology_baseline_LogisticRegression', 'w2v_radiology_baseline_MLP', 'w2v_radiology_baseline_NaiveBayes', 'w2v_radiology_baseline_RandomForest', 'w2v_radiology_baseline_SVC', 'w2v_radiology_baseline_XGB', 'w2v_optimized_radiology_CatBoost', 'w2v_optimized_radiology_GradientBoosting', 'w2v_optimized_radiology_LGBM', 'w2v_optimized_radiology_LogisticRegression', 'w2v_optimized_radiology_RandomForest', 'w2v_optimized_radiology_XGB']\n",
      "SMOTE keys: ['original_baseline_CatBoost_smote_baseline', 'original_baseline_DecisionTree_smote_baseline', 'original_baseline_GradientBoosting_smote_baseline', 'original_baseline_LGBM_smote_baseline', 'original_baseline_LogisticRegression_smote_baseline', 'original_baseline_MLP_smote_baseline', 'original_baseline_NaiveBayes_smote_baseline', 'original_baseline_RandomForest_smote_baseline', 'original_baseline_SVC_smote_baseline', 'original_baseline_XGB_smote_baseline', 'w2v_radiology_baseline_CatBoost_smote_baseline', 'w2v_radiology_baseline_DecisionTree_smote_baseline', 'w2v_radiology_baseline_GradientBoosting_smote_baseline', 'w2v_radiology_baseline_LGBM_smote_baseline', 'w2v_radiology_baseline_LogisticRegression_smote_baseline', 'w2v_radiology_baseline_MLP_smote_baseline', 'w2v_radiology_baseline_NaiveBayes_smote_baseline', 'w2v_radiology_baseline_RandomForest_smote_baseline', 'w2v_radiology_baseline_SVC_smote_baseline', 'w2v_radiology_baseline_XGB_smote_baseline', 'w2v_optimized_radiology_CatBoost_smote', 'w2v_optimized_radiology_GradientBoosting_smote', 'w2v_optimized_radiology_LGBM_smote', 'w2v_optimized_radiology_LogisticRegression_smote', 'w2v_optimized_radiology_RandomForest_smote', 'w2v_optimized_radiology_XGB_smote']\n",
      "üíæ Logged loaded models manifest ‚Üí C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\results\\models\\comparisons\\loaded_models_manifest.json\n",
      "‚úÖ Cleaned and overwrote data_w2v_optimized_radiology_xtrain.csv (X_train; dropped id/flags)\n",
      "‚úÖ Cleaned and overwrote data_w2v_optimized_radiology_xtrain_res.csv (X_train_resampled; dropped id/flags)\n",
      "‚úÖ Cleaned and overwrote data_w2v_optimized_radiology_xtest.csv (X_test; dropped id/flags)\n",
      "‚úÖ Loaded test data for original: (1042, 43)\n",
      "‚úÖ Loaded test data for w2v_radiology: (1042, 143)\n",
      "‚úÖ Loaded test data for w2v_optimized_radiology: (1042, 143)\n",
      "üì¶ Created samples for 3 variants ‚Üí ['original', 'w2v_radiology', 'w2v_optimized_radiology']\n",
      "‚úÖ Generalization gap summary saved ‚Üí C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\results\\evaluation\\20251217\\final_generalization_gap_summary.csv\n",
      "üìÅ Calibration figures will be saved to: C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\results\\figures\\calibration\n",
      "\n",
      "üìè Calibration: CatBoost (w2v_optimized_radiology)\n",
      "üìä Saved ‚Üí C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\results\\figures\\w2v_optimized_radiology\\calibrations\\calibration_w2v_optimized_radiology_CatBoost.png\n",
      "Saved calibration plot for optimized variant: CatBoost\n",
      "\n",
      "üìè Calibration: GradientBoosting (w2v_optimized_radiology)\n",
      "üìä Saved ‚Üí C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\results\\figures\\w2v_optimized_radiology\\calibrations\\calibration_w2v_optimized_radiology_GradientBoosting.png\n",
      "Saved calibration plot for optimized variant: GradientBoosting\n",
      "\n",
      "üìè Calibration: LGBM (w2v_optimized_radiology)\n",
      "üìä Saved ‚Üí C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\results\\figures\\w2v_optimized_radiology\\calibrations\\calibration_w2v_optimized_radiology_LGBM.png\n",
      "Saved calibration plot for optimized variant: LGBM\n",
      "\n",
      "üìè Calibration: LogisticRegression (w2v_optimized_radiology)\n",
      "üìä Saved ‚Üí C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\results\\figures\\w2v_optimized_radiology\\calibrations\\calibration_w2v_optimized_radiology_LogisticRegression.png\n",
      "Saved calibration plot for optimized variant: LogisticRegression\n",
      "\n",
      "üìè Calibration: RandomForest (w2v_optimized_radiology)\n",
      "üìä Saved ‚Üí C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\results\\figures\\w2v_optimized_radiology\\calibrations\\calibration_w2v_optimized_radiology_RandomForest.png\n",
      "Saved calibration plot for optimized variant: RandomForest\n",
      "\n",
      "üìè Calibration: XGB (w2v_optimized_radiology)\n",
      "üìä Saved ‚Üí C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\results\\figures\\w2v_optimized_radiology\\calibrations\\calibration_w2v_optimized_radiology_XGB.png\n",
      "Saved calibration plot for optimized variant: XGB\n",
      "‚úÖ Calibration summary saved ‚Üí C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\results\\figures\\calibration\\calibration_summary_optimized.csv\n",
      "Œî mean(|prob diff|) ‚Äî LogisticRegression (w2v_optimized_radiology vs w2v_radiology): 0.036401\n",
      "Œî mean(|prob diff|) ‚Äî LogisticRegression (w2v_optimized_radiology vs original): 0.073508\n",
      "‚ö†Ô∏è Missing model keys for DecisionTree (w2v_optimized_radiology vs w2v_radiology).\n",
      "‚ö†Ô∏è Missing model keys for DecisionTree (w2v_optimized_radiology vs original).\n",
      "Œî mean(|prob diff|) ‚Äî RandomForest      (w2v_optimized_radiology vs w2v_radiology): 0.026087\n",
      "Œî mean(|prob diff|) ‚Äî RandomForest      (w2v_optimized_radiology vs original): 0.049372\n",
      "Œî mean(|prob diff|) ‚Äî GradientBoosting  (w2v_optimized_radiology vs w2v_radiology): 0.059748\n",
      "Œî mean(|prob diff|) ‚Äî GradientBoosting  (w2v_optimized_radiology vs original): 0.079842\n",
      "Œî mean(|prob diff|) ‚Äî XGB               (w2v_optimized_radiology vs w2v_radiology): 0.050704\n",
      "Œî mean(|prob diff|) ‚Äî XGB               (w2v_optimized_radiology vs original): 0.104675\n",
      "Œî mean(|prob diff|) ‚Äî LGBM              (w2v_optimized_radiology vs w2v_radiology): 0.057703\n",
      "Œî mean(|prob diff|) ‚Äî LGBM              (w2v_optimized_radiology vs original): 0.089241\n",
      "Œî mean(|prob diff|) ‚Äî CatBoost          (w2v_optimized_radiology vs w2v_radiology): 0.049372\n",
      "Œî mean(|prob diff|) ‚Äî CatBoost          (w2v_optimized_radiology vs original): 0.076646\n",
      "‚ö†Ô∏è Missing model keys for SVC (w2v_optimized_radiology vs w2v_radiology).\n",
      "‚ö†Ô∏è Missing model keys for SVC (w2v_optimized_radiology vs original).\n",
      "‚ö†Ô∏è Missing model keys for MLP (w2v_optimized_radiology vs w2v_radiology).\n",
      "‚ö†Ô∏è Missing model keys for MLP (w2v_optimized_radiology vs original).\n",
      "‚ö†Ô∏è Missing model keys for NaiveBayes (w2v_optimized_radiology vs w2v_radiology).\n",
      "‚ö†Ô∏è Missing model keys for NaiveBayes (w2v_optimized_radiology vs original).\n",
      "\n",
      "üèÅ Completed Sections 14‚Äì16: Calibration, Brier Scores, and Optimized Model Comparisons.\n",
      "\n",
      "üîÅ Starting calibration and probability comparison for SMOTE models\n",
      "üîç Calibration for CatBoost (w2v_optimized_radiology_CatBoost) [SMOTE]\n",
      "üìä Saved ‚Üí C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\results\\figures\\w2v_optimized_radiology_smote\\calibrations\\calibration_w2v_optimized_radiology_smote_CatBoost.png\n",
      "Saved calibration plot for optimized SMOTE variant: CatBoost\n",
      "üîç Calibration for GradientBoosting (w2v_optimized_radiology_GradientBoosting) [SMOTE]\n",
      "üìä Saved ‚Üí C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\results\\figures\\w2v_optimized_radiology_smote\\calibrations\\calibration_w2v_optimized_radiology_smote_GradientBoosting.png\n",
      "Saved calibration plot for optimized SMOTE variant: GradientBoosting\n",
      "üîç Calibration for LGBM (w2v_optimized_radiology_LGBM) [SMOTE]\n",
      "üìä Saved ‚Üí C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\results\\figures\\w2v_optimized_radiology_smote\\calibrations\\calibration_w2v_optimized_radiology_smote_LGBM.png\n",
      "Saved calibration plot for optimized SMOTE variant: LGBM\n",
      "üîç Calibration for LogisticRegression (w2v_optimized_radiology_LogisticRegression) [SMOTE]\n",
      "üìä Saved ‚Üí C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\results\\figures\\w2v_optimized_radiology_smote\\calibrations\\calibration_w2v_optimized_radiology_smote_LogisticRegression.png\n",
      "Saved calibration plot for optimized SMOTE variant: LogisticRegression\n",
      "üîç Calibration for RandomForest (w2v_optimized_radiology_RandomForest) [SMOTE]\n",
      "üìä Saved ‚Üí C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\results\\figures\\w2v_optimized_radiology_smote\\calibrations\\calibration_w2v_optimized_radiology_smote_RandomForest.png\n",
      "Saved calibration plot for optimized SMOTE variant: RandomForest\n",
      "üîç Calibration for XGB (w2v_optimized_radiology_XGB) [SMOTE]\n",
      "üìä Saved ‚Üí C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\results\\figures\\w2v_optimized_radiology_smote\\calibrations\\calibration_w2v_optimized_radiology_smote_XGB.png\n",
      "Saved calibration plot for optimized SMOTE variant: XGB\n",
      "‚úÖ SMOTE calibration summary saved ‚Üí C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\results\\figures\\calibration\\calibration_summary_optimized_smote.csv\n",
      "Œî mean(|prob diff|) [SMOTE] ‚Äî LogisticRegression (w2v_optimized_radiology vs w2v_radiology): 0.072129\n",
      "Œî mean(|prob diff|) [SMOTE] ‚Äî LogisticRegression (w2v_optimized_radiology vs original): 0.122923\n",
      "‚ö†Ô∏è Missing model keys for DecisionTree (w2v_optimized_radiology vs w2v_radiology) [SMOTE].\n",
      "‚ö†Ô∏è Missing model keys for DecisionTree (w2v_optimized_radiology vs original) [SMOTE].\n",
      "Œî mean(|prob diff|) [SMOTE] ‚Äî RandomForest      (w2v_optimized_radiology vs w2v_radiology): 0.067661\n",
      "Œî mean(|prob diff|) [SMOTE] ‚Äî RandomForest      (w2v_optimized_radiology vs original): 0.104930\n",
      "Œî mean(|prob diff|) [SMOTE] ‚Äî GradientBoosting  (w2v_optimized_radiology vs w2v_radiology): 0.104942\n",
      "Œî mean(|prob diff|) [SMOTE] ‚Äî GradientBoosting  (w2v_optimized_radiology vs original): 0.165182\n",
      "Œî mean(|prob diff|) [SMOTE] ‚Äî XGB               (w2v_optimized_radiology vs w2v_radiology): 0.062044\n",
      "Œî mean(|prob diff|) [SMOTE] ‚Äî XGB               (w2v_optimized_radiology vs original): 0.172665\n",
      "Œî mean(|prob diff|) [SMOTE] ‚Äî LGBM              (w2v_optimized_radiology vs w2v_radiology): 0.068137\n",
      "Œî mean(|prob diff|) [SMOTE] ‚Äî LGBM              (w2v_optimized_radiology vs original): 0.108406\n",
      "Œî mean(|prob diff|) [SMOTE] ‚Äî CatBoost          (w2v_optimized_radiology vs w2v_radiology): 0.063632\n",
      "Œî mean(|prob diff|) [SMOTE] ‚Äî CatBoost          (w2v_optimized_radiology vs original): 0.111059\n",
      "‚ö†Ô∏è Missing model keys for SVC (w2v_optimized_radiology vs w2v_radiology) [SMOTE].\n",
      "‚ö†Ô∏è Missing model keys for SVC (w2v_optimized_radiology vs original) [SMOTE].\n",
      "‚ö†Ô∏è Missing model keys for MLP (w2v_optimized_radiology vs w2v_radiology) [SMOTE].\n",
      "‚ö†Ô∏è Missing model keys for MLP (w2v_optimized_radiology vs original) [SMOTE].\n",
      "‚ö†Ô∏è Missing model keys for NaiveBayes (w2v_optimized_radiology vs w2v_radiology) [SMOTE].\n",
      "‚ö†Ô∏è Missing model keys for NaiveBayes (w2v_optimized_radiology vs original) [SMOTE].\n",
      "\n",
      "üèÅ Completed SMOTE calibration, Brier score, and optimized vs baseline probability comparisons.\n",
      "\n",
      "======================================================================\n",
      "üèÅ Final model evaluation completed and logged to MLflow.\n",
      "üìÇ Experiment: Thesis_ModelTraining\n",
      "üïí Run end time: 2025-12-17 12:33:03\n",
      "üì¶ Artifacts logged under: C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\mlflow_tracking\n",
      "======================================================================\n",
      "\n",
      "‚úÖ MLflow run closed successfully.\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# Full Evaluation with MLflow Logging\n",
    "# ==================================================\n",
    "\n",
    "# --- Set up MLflow experiment (same as training phase) ---\n",
    "tracking_dir = resolve_path(\"mlflow_tracking\")\n",
    "mlflow.set_tracking_uri(tracking_dir.as_uri())\n",
    "\n",
    "experiment_name = \"Thesis_ModelTraining\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "with mlflow.start_run(run_name=\"final_model_evaluation\", nested=False):\n",
    "    print(f\"‚úÖ MLflow evaluation run started under experiment '{experiment_name}'\")\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Aggregate & Compare Results vs Baseline + Original\n",
    "    # --------------------------------------------------\n",
    "    summary_orig = pd.read_csv(resolve_path(\"reports/20251027/original_baseline_20251027_summary.csv\"))\n",
    "    summary_w2v_radiology = pd.read_csv(resolve_path(\"reports/20251027/w2v_radiology_baseline_20251027_summary.csv\"))\n",
    "    summary_w2v_opt_radiology = pd.read_csv(resolve_path(\"reports/20251028/w2v_optimized_radiology_20251028_summary.csv\"))\n",
    "    \n",
    "    for df, tag in [\n",
    "        (summary_orig, \"original\"),\n",
    "        (summary_w2v_radiology, \"w2v_radiology\"),\n",
    "        (summary_w2v_opt_radiology, \"w2v_optimized_radiology\"),\n",
    "    ]:\n",
    "        df[\"Dataset\"] = tag\n",
    "    \n",
    "    comparison_all = pd.concat(\n",
    "        [summary_orig, summary_w2v_radiology, summary_w2v_opt_radiology],\n",
    "        ignore_index=True\n",
    "    )\n",
    "    \n",
    "    comparison_path = resolve_path(\"results/evaluation/opt_model_comparison_summary.csv\")\n",
    "    os.makedirs(os.path.dirname(comparison_path), exist_ok=True)\n",
    "    comparison_all.to_csv(comparison_path, index=False)\n",
    "    mlflow.log_artifact(str(comparison_path), artifact_path=\"summaries\")\n",
    "    print(f\"üíæ Saved and logged merged model comparison summary to {comparison_path}\")\n",
    "    \n",
    "    # --------------------------------------------------\n",
    "    # Evaluate & Visualize Performance vs Prior Models\n",
    "    # --------------------------------------------------\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    \n",
    "    def _fix_legend(ax):\n",
    "        \"\"\"Prettier legend labels for Dataset.\"\"\"\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        label_map = {\n",
    "            \"original\": \"Structured Only\",\n",
    "            \"w2v_radiology\": \"Structured + Baseline Word2Vec\",\n",
    "            \"w2v_optimized_radiology\": \"Structured + Optimized Word2Vec\",\n",
    "        }\n",
    "        pretty_labels = [label_map.get(lbl, lbl) for lbl in labels]\n",
    "        ax.legend(\n",
    "            handles,\n",
    "            pretty_labels,\n",
    "            title=\"Model variant\",\n",
    "            bbox_to_anchor=(1.02, 1),\n",
    "            loc=\"upper left\",\n",
    "            borderaxespad=0.0,\n",
    "        )\n",
    "    \n",
    "    def plot_holdout_for_column(score_col, title_suffix, rel_path):\n",
    "        \"\"\"\n",
    "        score_col: column name in comparison_all (e.g. 'Holdout ROC-AUC' or 'Holdout ROC-AUC (SMOTE)')\n",
    "        title_suffix: string like 'Non-SMOTE' or 'SMOTE'\n",
    "        rel_path: relative path (under project root) where the PNG should be saved\n",
    "        \"\"\"\n",
    "        if score_col not in comparison_all.columns:\n",
    "            raise KeyError(f\"{score_col!r} not found in comparison_all columns: {comparison_all.columns.tolist()}\")\n",
    "    \n",
    "        # Work on a copy, but only keep the columns we actually need\n",
    "        plot_df = comparison_all.loc[:, [\"Classifier\", \"Dataset\", score_col]].copy()\n",
    "        plot_df = plot_df.rename(columns={score_col: \"Holdout ROC-AUC\"})\n",
    "    \n",
    "        # Optional: drop rows where this metric is missing\n",
    "        plot_df = plot_df.dropna(subset=[\"Holdout ROC-AUC\"])\n",
    "    \n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        sns.barplot(\n",
    "            data=plot_df,\n",
    "            x=\"Classifier\",\n",
    "            y=\"Holdout ROC-AUC\",\n",
    "            hue=\"Dataset\",\n",
    "            ax=ax,\n",
    "        )\n",
    "        ax.set_title(f\"Holdout AUROC Across Dataset Variants ({title_suffix})\")\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\")\n",
    "    \n",
    "        _fix_legend(ax)\n",
    "    \n",
    "        fig_path = resolve_path(rel_path)\n",
    "        os.makedirs(os.path.dirname(fig_path), exist_ok=True)\n",
    "        fig.savefig(fig_path, bbox_inches=\"tight\", dpi=300)\n",
    "        mlflow.log_artifact(str(fig_path), artifact_path=\"plots\")\n",
    "        plt.close(fig)\n",
    "        print(f\"üìä Logged {title_suffix} comparison bar plot to MLflow and saved to {fig_path}\")\n",
    "\n",
    "        ax.set_title(f\"Holdout AUROC Across Dataset Variants ({title_suffix})\")\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\")\n",
    "    \n",
    "        _fix_legend(ax)\n",
    "    \n",
    "        fig_path = resolve_path(rel_path)\n",
    "        os.makedirs(os.path.dirname(fig_path), exist_ok=True)\n",
    "        fig.savefig(fig_path, bbox_inches=\"tight\", dpi=300)\n",
    "        mlflow.log_artifact(str(fig_path), artifact_path=\"plots\")\n",
    "        plt.close(fig)\n",
    "        print(f\"üìä Logged {title_suffix} comparison bar plot to MLflow and saved to {fig_path}\")\n",
    "    \n",
    "    # Non-SMOTE version (uses the original non-SMOTE column)\n",
    "    plot_holdout_for_column(\n",
    "        score_col=\"Holdout ROC-AUC\",\n",
    "        title_suffix=\"Non-SMOTE\",\n",
    "        rel_path=\"results/plots/w2v_optimized_radiology/holdout_auroc_comparison_non_smote.png\",\n",
    "    )\n",
    "    \n",
    "    # SMOTE version (uses the SMOTE column that already exists in the same CSVs)\n",
    "    plot_holdout_for_column(\n",
    "        score_col=\"Holdout ROC-AUC (SMOTE)\",\n",
    "        title_suffix=\"SMOTE\",\n",
    "        rel_path=\"results/plots/w2v_optimized_radiology/holdout_auroc_comparison_smote.png\",\n",
    "    )\n",
    "\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Summarize & Export Final Metrics for Thesis\n",
    "    # --------------------------------------------------\n",
    "    from src.evaluation import export_summary\n",
    "    from datetime import datetime\n",
    "    \n",
    "    # Aggregate mean ROC-AUC metrics per dataset\n",
    "    final_summary = (\n",
    "        comparison_all.groupby([\"Dataset\"], as_index=False)[\n",
    "            [\"Holdout ROC-AUC\", \"Holdout ROC-AUC (SMOTE)\"]\n",
    "        ]\n",
    "        .mean()\n",
    "        .round(4)\n",
    "    )\n",
    "    \n",
    "    # Use project-standard export_summary() to save with timestamp\n",
    "    final_export_path = export_summary(\n",
    "        final_summary,\n",
    "        mode=\"final_model_summary\",\n",
    "        save_prefix=resolve_path(\"results/evaluation\"),\n",
    "        include_time=False\n",
    "    )\n",
    "    \n",
    "    # Log the generated summary CSV to MLflow\n",
    "    mlflow.log_artifact(str(final_export_path), artifact_path=\"exports\")\n",
    "    \n",
    "    # --------------------------------------------------\n",
    "    # Log key AUC deltas for dashboarding\n",
    "    # --------------------------------------------------\n",
    "    auc_opt = final_summary.loc[final_summary[\"Dataset\"] == \"w2v_optimized_radiology\", \"Holdout ROC-AUC\"].values[0]\n",
    "    auc_w2v = final_summary.loc[final_summary[\"Dataset\"] == \"w2v_radiology\", \"Holdout ROC-AUC\"].values[0]\n",
    "    auc_orig = final_summary.loc[final_summary[\"Dataset\"] == \"original\", \"Holdout ROC-AUC\"].values[0]\n",
    "    \n",
    "    # Primary: optimized vs original baseline\n",
    "    delta_auc_primary = auc_opt - auc_orig\n",
    "    mlflow.log_metric(\"delta_auc_optimized_vs_original\", float(delta_auc_primary))\n",
    "    print(f\"Logged ŒîAUROC (optimized vs original) = {delta_auc_primary:.4f}\")\n",
    "    \n",
    "    # Secondary: optimized vs W2V baseline\n",
    "    delta_auc_secondary = auc_opt - auc_w2v\n",
    "    mlflow.log_metric(\"delta_auc_optimized_vs_w2v_baseline\", float(delta_auc_secondary))\n",
    "    print(f\"Logged ŒîAUROC (optimized vs w2v baseline) = {delta_auc_secondary:.4f}\")\n",
    "\n",
    "\n",
    "    # ==================================================\n",
    "    # From 06 10 Load Top Models (Baseline + Optimized Variants)\n",
    "    # ==================================================\n",
    "    print(\"\\nüì¶ Loading all baseline and optimized W2V models for evaluation and interpretation\")\n",
    "    \n",
    "    # ----------------------------------------------------------\n",
    "    # 1Ô∏è‚É£ Setup\n",
    "    # ----------------------------------------------------------\n",
    "    model_variants = [\n",
    "        \"original_baseline\",\n",
    "        \"w2v_radiology_baseline\",\n",
    "        \"w2v_optimized_radiology\"\n",
    "    ]\n",
    "    loaded_models_baseline, loaded_models_smote = {}, {}\n",
    "    \n",
    "    # ----------------------------------------------------------\n",
    "    # 2Ô∏è‚É£ Locate and load all *_model.pkl files\n",
    "    # ----------------------------------------------------------\n",
    "    for variant in model_variants:\n",
    "        variant_dir = Path(resolve_path(f\"results/models/{variant}\"))\n",
    "        if not variant_dir.exists():\n",
    "            print(f\"‚ö†Ô∏è No results directory found for {variant} ‚Üí {variant_dir}\")\n",
    "            continue\n",
    "    \n",
    "        subdirs = sorted(\n",
    "            [p for p in variant_dir.iterdir() if p.is_dir()],\n",
    "            key=lambda x: x.stat().st_mtime,\n",
    "            reverse=True\n",
    "        )\n",
    "        if not subdirs:\n",
    "            print(f\"‚ö†Ô∏è No run folders found for {variant}\")\n",
    "            continue\n",
    "    \n",
    "        latest_run = subdirs[0]\n",
    "        print(f\"üìÇ Using latest run folder for {variant} ‚Üí {latest_run.name}\")\n",
    "    \n",
    "        pattern = str(resolve_path(f\"{latest_run}/*.pkl\"))\n",
    "        all_model_files = [\n",
    "            f for f in glob.glob(pattern)\n",
    "            if \"_model.pkl\" in f and \"_full\" not in f\n",
    "        ]\n",
    "        if not all_model_files:\n",
    "            print(f\"‚ö†Ô∏è No individual model.pkl files found in {latest_run}\")\n",
    "            continue\n",
    "    \n",
    "        for file in all_model_files:\n",
    "            file_path = Path(file)\n",
    "            name = file_path.stem\n",
    "\n",
    "            # --- Skip any \"best\" model files (avoid duplicates / meta-wrappers) ---\n",
    "            if \"best\" in name.lower():\n",
    "                print(f\"‚è≠Ô∏è  Skipping best model file: {file_path.name}\")\n",
    "                continue\n",
    "\n",
    "        \n",
    "            # üö´ Skip any \"_best\" models entirely\n",
    "            if name.endswith(\"_best_model\") or name.endswith(\"_best\"):\n",
    "                print(f\"‚è≠Ô∏è Skipping {name} (best model variant)\")\n",
    "                continue\n",
    "        \n",
    "            model = joblib.load(file_path)\n",
    "            parts = name.split(\"_\")\n",
    "        \n",
    "            # Detect classifier and SMOTE status\n",
    "            if name.lower().endswith(\"smote_model\"):\n",
    "                clf_name = parts[-3]\n",
    "                # Keep \"_baseline\" suffix only for the first two variants\n",
    "                key = (\n",
    "                    f\"{variant}_{clf_name}_smote\"\n",
    "                    if \"optimized\" in variant\n",
    "                    else f\"{variant}_{clf_name}_smote_baseline\"\n",
    "                )\n",
    "                loaded_models_smote[key] = model\n",
    "                tag = \"SMOTE\"\n",
    "            else:\n",
    "                clf_name = parts[-2]\n",
    "                key = (\n",
    "                    f\"{variant}_{clf_name}\"\n",
    "                    if \"optimized\" in variant\n",
    "                    else f\"{variant}_{clf_name}\"\n",
    "                )\n",
    "                loaded_models_baseline[key] = model\n",
    "                tag = \"Baseline\"\n",
    "        \n",
    "            print(f\"‚úÖ Loaded {clf_name:<18} | {tag}\")\n",
    "\n",
    "    \n",
    "    # ----------------------------------------------------------\n",
    "    # 3Ô∏è‚É£ Unwrap nested estimators\n",
    "    # ----------------------------------------------------------\n",
    "    loaded_models_baseline = unwrap_best_estimators_non_smote(loaded_models_baseline)\n",
    "    loaded_models_smote    = unwrap_best_estimators_smote(loaded_models_smote)\n",
    "\n",
    "    # Remove any lingering ‚Äúbest‚Äù keys (safety)\n",
    "    loaded_models_baseline = {k: v for k, v in loaded_models_baseline.items() if not k.endswith(\"_best\")}\n",
    "    loaded_models_smote = {k: v for k, v in loaded_models_smote.items() if not k.endswith(\"_best\")}\n",
    "\n",
    "    \n",
    "    # ----------------------------------------------------------\n",
    "    # 4Ô∏è‚É£ Summary + manifest\n",
    "    # ----------------------------------------------------------\n",
    "    print(\"\\nüìä Summary of loaded models\")\n",
    "    print(f\"Baseline models ‚Üí {len(loaded_models_baseline)}\")\n",
    "    print(f\"SMOTE models    ‚Üí {len(loaded_models_smote)}\")\n",
    "    print(\"Baseline keys:\", list(loaded_models_baseline.keys()))\n",
    "    print(\"SMOTE keys:\", list(loaded_models_smote.keys()))\n",
    "    \n",
    "    manifest = {\n",
    "        \"baseline_keys\": list(loaded_models_baseline.keys()),\n",
    "        \"smote_keys\": list(loaded_models_smote.keys()),\n",
    "    }\n",
    "    manifest_path = Path(resolve_path(\"results/models/comparisons/loaded_models_manifest.json\"))\n",
    "    manifest_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(manifest_path, \"w\") as f:\n",
    "        json.dump(manifest, f, indent=2)\n",
    "    mlflow.log_artifact(str(manifest_path), artifact_path=\"summaries\")\n",
    "    print(f\"üíæ Logged loaded models manifest ‚Üí {manifest_path}\")\n",
    "\n",
    "    # ==================================================\n",
    "    # From 06 12 Prepare Representative Sample Data\n",
    "    # ==================================================\n",
    "    \n",
    "    # --------------------------------------------------\n",
    "    # Drop unwanted columns from optimized variant (clean before load)\n",
    "    # --------------------------------------------------\n",
    "    drop_cols = [\"first_hosp_stay\", \"suspected_infection\", \"sepsis3\", \"subject_id\"]\n",
    "    \n",
    "    # Paths for optimized variant datasets\n",
    "    opt_train_path = resolve_path(\"data/processed/w2v_optimized_radiology/data_w2v_optimized_radiology_xtrain.csv\")\n",
    "    opt_train_res_path = resolve_path(\"data/processed/w2v_optimized_radiology/data_w2v_optimized_radiology_xtrain_res.csv\")\n",
    "    opt_test_path = resolve_path(\"data/processed/w2v_optimized_radiology/data_w2v_optimized_radiology_xtest.csv\")\n",
    "    \n",
    "    def clean_and_overwrite(path: Path, label: str):\n",
    "        if path.exists():\n",
    "            df = pd.read_csv(path)\n",
    "            df = df.drop(columns=[c for c in drop_cols if c in df.columns], errors=\"ignore\")\n",
    "            df.to_csv(path, index=False)\n",
    "            print(f\"‚úÖ Cleaned and overwrote {path.name} ({label}; dropped id/flags)\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Missing file for {label} ‚Üí {path}\")\n",
    "    \n",
    "    # Clean all optimized variant datasets first\n",
    "    clean_and_overwrite(opt_train_path, \"X_train\")\n",
    "    clean_and_overwrite(opt_train_res_path, \"X_train_resampled\")\n",
    "    clean_and_overwrite(opt_test_path, \"X_test\")\n",
    "    \n",
    "    \n",
    "    # --------------------------------------------------\n",
    "    # Now load processed test data (all three variants)\n",
    "    # --------------------------------------------------\n",
    "    variants = [\"original\", \"w2v_radiology\", \"w2v_optimized_radiology\"]\n",
    "    X_tests, y_tests = {}, {}\n",
    "    \n",
    "    for variant in variants:\n",
    "        x_path = resolve_path(f\"data/processed/{variant}/data_{variant}_xtest.csv\")\n",
    "        y_path = resolve_path(f\"data/processed/{variant}/data_{variant}_ytest.csv\")\n",
    "    \n",
    "        if x_path.exists() and y_path.exists():\n",
    "            X_tests[variant] = pd.read_csv(x_path)\n",
    "            y_tests[variant] = pd.read_csv(y_path).squeeze()\n",
    "            print(f\"‚úÖ Loaded test data for {variant}: {X_tests[variant].shape}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Missing test data for {variant}\")\n",
    "\n",
    "    # --- Create representative samples for SHAP/visualization ---\n",
    "    X_samples = {\n",
    "        v: X_tests[v].sample(n=min(1500, len(X_tests[v])), random_state=42)\n",
    "        for v in X_tests\n",
    "    }\n",
    "    print(f\"üì¶ Created samples for {len(X_samples)} variants ‚Üí {list(X_samples.keys())}\")\n",
    "\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    #  10.3‚Äì10.4 Additions ‚Äî Generalization Gap + Final Holdout Visuals\n",
    "    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    \n",
    "    # Load existing descriptive CV (baseline) and holdout (optimized) summaries\n",
    "    baseline_df = pd.read_csv(resolve_path(\"reports/20251027/baseline_comparison_20251027.csv\"))\n",
    "    optimized_df = pd.read_csv(resolve_path(\"reports/20251028/w2v_optimized_radiology_20251028_summary.csv\"))\n",
    "    \n",
    "    # Clean column names without inplace mutation\n",
    "    baseline_df = baseline_df.rename(columns=lambda c: c.strip())\n",
    "    optimized_df = optimized_df.rename(columns=lambda c: c.strip())\n",
    "\n",
    "    \n",
    "    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    # Merge baseline + optimized summaries (include stds)\n",
    "    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    merged = baseline_df[[\n",
    "        \"Classifier\",\n",
    "        \"Descriptive CV Mean AUC\",\n",
    "        \"Descriptive CV Std AUC\",\n",
    "        \"Descriptive CV Mean AUC (SMOTE)\",\n",
    "        \"Descriptive CV Std AUC (SMOTE)\",\n",
    "        \"Holdout ROC-AUC\",\n",
    "        \"Final Holdout ROC-AUC (SMOTE)\"\n",
    "    ]].copy()\n",
    "    \n",
    "    # Compute all three generalization gaps\n",
    "    merged[\"ŒîAUROC_nonSMOTE\"] = merged[\"Holdout ROC-AUC\"] - merged[\"Descriptive CV Mean AUC\"]\n",
    "    merged[\"ŒîAUROC_SMOTE\"] = merged[\"Final Holdout ROC-AUC (SMOTE)\"] - merged[\"Descriptive CV Mean AUC (SMOTE)\"]\n",
    "    merged[\"ŒîAUROC_SMOTE_vs_nonSMOTE_CV\"] = merged[\"Final Holdout ROC-AUC (SMOTE)\"] - merged[\"Descriptive CV Mean AUC\"]\n",
    "    \n",
    "    # Retain stds for reporting\n",
    "    merged.rename(columns={\n",
    "        \"Descriptive CV Std AUC\": \"CV_Std_nonSMOTE\",\n",
    "        \"Descriptive CV Std AUC (SMOTE)\": \"CV_Std_SMOTE\"\n",
    "    }, inplace=True)\n",
    "    \n",
    "    today = datetime.now().strftime(\"%Y%m%d\")\n",
    "    eval_dir = f\"results/evaluation/{today}\"\n",
    "    plot_dir = f\"results/plots/final_holdout/{today}\"\n",
    "    os.makedirs(eval_dir, exist_ok=True)\n",
    "    os.makedirs(plot_dir, exist_ok=True)\n",
    "    gap_path = resolve_path(f\"{eval_dir}/final_generalization_gap_summary.csv\")\n",
    "    merged.to_csv(gap_path, index=False)\n",
    "    print(f\"‚úÖ Generalization gap summary saved ‚Üí {gap_path}\")\n",
    "\n",
    "    # ==================================================\n",
    "    # Post-load: Generate ROC/PR/holdout plots (10.3‚Äì10.4)\n",
    "    # ==================================================\n",
    "    plot_dir = f\"results/plots/final_holdout/{today}\"\n",
    "    os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "    # -----------------------------\n",
    "    # 1Ô∏è‚É£ Non-SMOTE optimized W2V\n",
    "    # -----------------------------\n",
    "    variant = \"w2v_optimized_radiology\"\n",
    "\n",
    "    optimized_models_non_smote = {\n",
    "        k: v for k, v in loaded_models_baseline.items() if variant in k\n",
    "    }\n",
    "\n",
    "    plot_roc_curves(\n",
    "        optimized_models_non_smote,\n",
    "        X_tests[variant],\n",
    "        y_tests[variant],\n",
    "        mode=variant,\n",
    "    )\n",
    "\n",
    "    plot_pr(\n",
    "        optimized_models_non_smote,\n",
    "        X_tests[variant],\n",
    "        y_tests[variant],\n",
    "        mode=variant,\n",
    "    )\n",
    "\n",
    "    plot_bar_comparison(\n",
    "        all_models=[optimized_models_non_smote],\n",
    "        dataset_labels=[\"Optimized W2V Radiology\"],\n",
    "        X_tests=[X_tests[variant]],\n",
    "        y_tests=[y_tests[variant]],\n",
    "        metric=\"roc_auc\",\n",
    "        save_path=f\"{plot_dir}/holdout_auroc_comparison_{variant}.png\",\n",
    "        title=\"Holdout AUROC (Optimized W2V Radiology)\",\n",
    "    )\n",
    "\n",
    "   # -----------------------------\n",
    "    # 2Ô∏è‚É£ SMOTE optimized W2V\n",
    "    # -----------------------------\n",
    "    variant = \"w2v_optimized_radiology_smote\"\n",
    "    \n",
    "    # use the SMOTE model dict and match the real key pattern\n",
    "    optimized_models_smote = {\n",
    "        k: v\n",
    "        for k, v in loaded_models_smote.items()\n",
    "        if k.startswith(\"w2v_optimized_radiology_\") and k.endswith(\"_smote\")\n",
    "    }\n",
    "\n",
    "\n",
    "    if variant not in X_tests:\n",
    "        X_tests[variant] = X_tests[\"w2v_optimized_radiology\"]\n",
    "        y_tests[variant] = y_tests[\"w2v_optimized_radiology\"]\n",
    "        print(f\"‚ÑπÔ∏è Alias set: {variant} uses same test data as w2v_optimized_radiology.\")\n",
    "\n",
    "\n",
    "    plot_roc_curves(\n",
    "        optimized_models_smote,\n",
    "        X_tests[variant],\n",
    "        y_tests[variant],\n",
    "        mode=variant,\n",
    "    )\n",
    "\n",
    "    plot_pr(\n",
    "        optimized_models_smote,\n",
    "        X_tests[variant],\n",
    "        y_tests[variant],\n",
    "        mode=variant,\n",
    "    )\n",
    "\n",
    "    plot_bar_comparison(\n",
    "        all_models=[optimized_models_smote],\n",
    "        dataset_labels=[\"Optimized W2V SMOTE\"],\n",
    "        X_tests=[X_tests[variant]],\n",
    "        y_tests=[y_tests[variant]],\n",
    "        metric=\"roc_auc\",\n",
    "        save_path=f\"{plot_dir}/holdout_auroc_comparison_{variant}.png\",\n",
    "        title=\"Holdout AUROC (Optimized W2V SMOTE)\",\n",
    "    )\n",
    "\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    # ŒîAUROC Comparison Plot: Non-SMOTE, SMOTE, SMOTE vs Non-SMOTE CV\n",
    "    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    \n",
    "    # Collapse any duplicate classifier rows (e.g., from different variants)\n",
    "    merged_unique = (\n",
    "        merged.groupby(\"Classifier\", as_index=False)\n",
    "        .mean(numeric_only=True)\n",
    "        .sort_values(\"Classifier\")\n",
    "    )\n",
    "    \n",
    "    # Define output path\n",
    "    fig_path = resolve_path(f\"{plot_dir}/delta_auroc_comparison_grouped.png\")\n",
    "    os.makedirs(os.path.dirname(fig_path), exist_ok=True)\n",
    "    \n",
    "    # Extract plotting data\n",
    "    classifiers = merged_unique[\"Classifier\"]\n",
    "    bars = {\n",
    "        \"ŒîAUROC_nonSMOTE\": merged_unique[\"ŒîAUROC_nonSMOTE\"],\n",
    "        \"ŒîAUROC_SMOTE\": merged_unique[\"ŒîAUROC_SMOTE\"],\n",
    "        \"ŒîAUROC_SMOTE_vs_nonSMOTE_CV\": merged_unique[\"ŒîAUROC_SMOTE_vs_nonSMOTE_CV\"],\n",
    "    }\n",
    "    \n",
    "    # Plot setup\n",
    "    bar_width = 0.25\n",
    "    x = np.arange(len(classifiers))\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Colors and labels\n",
    "    colors = [\"#4472C4\", \"#ED7D31\", \"#A5A5A5\"]\n",
    "    labels = [\n",
    "        \"Non-SMOTE ‚Üí Holdout\",\n",
    "        \"SMOTE ‚Üí Holdout\",\n",
    "        \"SMOTE Holdout vs Non-SMOTE CV\",\n",
    "    ]\n",
    "    \n",
    "    # Plot grouped bars\n",
    "    for i, (key, color, label) in enumerate(zip(bars.keys(), colors, labels)):\n",
    "        plt.bar(x + i * bar_width, bars[key], width=bar_width, label=label, color=color, alpha=0.85)\n",
    "    \n",
    "    # Formatting\n",
    "    plt.axhline(0, color=\"black\", linewidth=1)\n",
    "    plt.xticks(x + bar_width, classifiers, rotation=45, ha=\"right\")\n",
    "    plt.ylabel(\"Œî AUROC (Holdout ‚àí CV)\")\n",
    "    plt.title(\"Generalization Gaps Across Classifiers\")\n",
    "    plt.legend()\n",
    "    plt.grid(axis=\"y\", alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save and display\n",
    "    plt.savefig(fig_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    print(f\"üìä ŒîAUROC grouped comparison chart saved ‚Üí {fig_path}\")\n",
    "    display(Image(filename=fig_path))\n",
    "\n",
    "    print(f\"‚úÖ Final holdout visualizations logged ‚Üí {plot_dir}\")\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    # ŒîAUROC Summary Statistics Table (includes original CV stds)\n",
    "    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    \n",
    "    # Build compact summary with original stds\n",
    "    summary_data = {\n",
    "        \"Metric\": [\n",
    "            \"Non-SMOTE ‚Üí Holdout\",\n",
    "            \"SMOTE ‚Üí Holdout\",\n",
    "            \"SMOTE Holdout vs Non-SMOTE CV\"\n",
    "        ],\n",
    "        \"CV Mean AUC\": [\n",
    "            merged[\"Descriptive CV Mean AUC\"].mean(),\n",
    "            merged[\"Descriptive CV Mean AUC (SMOTE)\"].mean(),\n",
    "            merged[\"Descriptive CV Mean AUC\"].mean()\n",
    "        ],\n",
    "        \"CV Std AUC\": [\n",
    "            merged[\"CV_Std_nonSMOTE\"].mean(),\n",
    "            merged[\"CV_Std_SMOTE\"].mean(),\n",
    "            merged[\"CV_Std_nonSMOTE\"].mean()\n",
    "        ],\n",
    "        \"Holdout Mean AUC\": [\n",
    "            merged[\"Holdout ROC-AUC\"].mean(),\n",
    "            merged[\"Final Holdout ROC-AUC (SMOTE)\"].mean(),\n",
    "            merged[\"Final Holdout ROC-AUC (SMOTE)\"].mean()\n",
    "        ],\n",
    "        \"ŒîAUROC (Mean)\": [\n",
    "            merged[\"ŒîAUROC_nonSMOTE\"].mean(),\n",
    "            merged[\"ŒîAUROC_SMOTE\"].mean(),\n",
    "            merged[\"ŒîAUROC_SMOTE_vs_nonSMOTE_CV\"].mean()\n",
    "        ],\n",
    "        \"ŒîAUROC (Std)\": [\n",
    "            merged[\"ŒîAUROC_nonSMOTE\"].std(),\n",
    "            merged[\"ŒîAUROC_SMOTE\"].std(),\n",
    "            merged[\"ŒîAUROC_SMOTE_vs_nonSMOTE_CV\"].std()\n",
    "        ],\n",
    "        \"Improved (Œî>0)\": [\n",
    "            int((merged[\"ŒîAUROC_nonSMOTE\"] > 0).sum()),\n",
    "            int((merged[\"ŒîAUROC_SMOTE\"] > 0).sum()),\n",
    "            int((merged[\"ŒîAUROC_SMOTE_vs_nonSMOTE_CV\"] > 0).sum())\n",
    "        ],\n",
    "        \"Decreased (Œî<0)\": [\n",
    "            int((merged[\"ŒîAUROC_nonSMOTE\"] < 0).sum()),\n",
    "            int((merged[\"ŒîAUROC_SMOTE\"] < 0).sum()),\n",
    "            int((merged[\"ŒîAUROC_SMOTE_vs_nonSMOTE_CV\"] < 0).sum())\n",
    "        ],\n",
    "    }\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    summary_df = summary_df.round({\n",
    "        \"CV Mean AUC\": 4,\n",
    "        \"CV Std AUC\": 4,\n",
    "        \"Holdout Mean AUC\": 4,\n",
    "        \"ŒîAUROC (Mean)\": 4,\n",
    "        \"ŒîAUROC (Std)\": 4\n",
    "    })\n",
    "    \n",
    "    # Display\n",
    "    display(summary_df.style.hide(axis=\"index\").set_caption(\"ŒîAUROC Generalization Summary (with Original CV Std)\"))\n",
    "    \n",
    "    # Save + log\n",
    "    summary_csv = resolve_path(f\"{eval_dir}/delta_auroc_summary_stats_with_std.csv\")\n",
    "    summary_df.to_csv(summary_csv, index=False)\n",
    "    print(f\"üìÑ ŒîAUROC summary table (with CV stds) saved ‚Üí {summary_csv}\")\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    # LaTeX Table Export ‚Äî ŒîAUROC Generalization Summary (with CV stds)\n",
    "    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    \n",
    "    # Build a copy for LaTeX with mean ¬± SD formatting\n",
    "    latex_df = summary_df.copy()\n",
    "    \n",
    "    # Combine CV mean ¬± std and ŒîAUROC mean ¬± std into single columns\n",
    "    latex_df[\"CV AUC (mean ¬± SD)\"] = (\n",
    "        latex_df[\"CV Mean AUC\"].map(\"{:.3f}\".format) + \" ¬± \" + latex_df[\"CV Std AUC\"].map(\"{:.3f}\".format)\n",
    "    )\n",
    "    latex_df[\"Holdout AUC\"] = latex_df[\"Holdout Mean AUC\"].map(\"{:.3f}\".format)\n",
    "    latex_df[\"ŒîAUROC (mean ¬± SD)\"] = (\n",
    "        latex_df[\"ŒîAUROC (Mean)\"].map(\"{:+.3f}\".format) + \" ¬± \" + latex_df[\"ŒîAUROC (Std)\"].map(\"{:.3f}\".format)\n",
    "    )\n",
    "    \n",
    "    # Subset for final display order\n",
    "    latex_cols = [\n",
    "        \"Metric\",\n",
    "        \"CV AUC (mean ¬± SD)\",\n",
    "        \"Holdout AUC\",\n",
    "        \"ŒîAUROC (mean ¬± SD)\",\n",
    "        \"Improved (Œî>0)\",\n",
    "        \"Decreased (Œî<0)\",\n",
    "    ]\n",
    "    latex_df = latex_df[latex_cols]\n",
    "    \n",
    "    # Convert to LaTeX tabular\n",
    "    latex_table = latex_df.to_latex(\n",
    "        index=False,\n",
    "        caption=\"Generalization gaps (ŒîAUROC) comparing internal descriptive cross-validation and holdout performance for non-SMOTE and SMOTE models.\",\n",
    "        label=\"tab:generalization_gaps\",\n",
    "        escape=False,\n",
    "        column_format=\"lcccccc\"\n",
    "    )\n",
    "    \n",
    "    # Save LaTeX file\n",
    "    latex_path = resolve_path(Path(eval_dir)) / \"delta_auroc_summary_table.tex\"\n",
    "    latex_path.write_text(latex_table, encoding=\"utf-8\")\n",
    "    print(f\"üìÑ LaTeX table exported ‚Üí {latex_path}\")\n",
    "\n",
    "    plt.close('all')\n",
    "\n",
    "    # Log all key artifacts to MLflow\n",
    "    mlflow.log_artifact(gap_path)\n",
    "    mlflow.log_artifact(fig_path)\n",
    "    mlflow.log_artifact(summary_csv)\n",
    "    mlflow.log_artifact(str(latex_path))\n",
    "    mlflow.log_artifacts(plot_dir)\n",
    "    \n",
    "    mlflow.log_metric(\"mean_ŒîAUROC_nonSMOTE\", round(merged[\"ŒîAUROC_nonSMOTE\"].mean(), 4))\n",
    "    mlflow.log_metric(\"mean_ŒîAUROC_SMOTE\", round(merged[\"ŒîAUROC_SMOTE\"].mean(), 4))\n",
    "    mlflow.log_metric(\"mean_ŒîAUROC_SMOTE_vs_nonSMOTE_CV\", round(merged[\"ŒîAUROC_SMOTE_vs_nonSMOTE_CV\"].mean(), 4))\n",
    "    \n",
    "    print(f\"\\n‚úÖ Logged all evaluation artifacts to MLflow under {plot_dir} and {eval_dir}\\n\")\n",
    "    \n",
    "    # ==================================================\n",
    "    # From 06 13a Compute SHAP Values and Coefficient Importances (Optimized W2V Non-SMOTE)\n",
    "    # ==================================================\n",
    "    print(\"\\nüìà Starting SHAP + Coefficient Explainability for optimized W2V NON-SMOTE models\")\n",
    "    \n",
    "    # Directory for all optimized explainability outputs (shared folder)\n",
    "    optimized_fig_dir = resolve_path(\"results/figures/w2v_optimized_radiology/\")\n",
    "    optimized_fig_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Filter only non-SMOTE optimized W2V models\n",
    "    optimized_models_non_smote = {\n",
    "        k: v for k, v in loaded_models_baseline.items()\n",
    "        if \"w2v_optimized_radiology\" in k\n",
    "    }\n",
    "    \n",
    "    if not optimized_models_non_smote:\n",
    "        print(\"‚ö†Ô∏è No optimized W2V non-SMOTE models found ‚Äî check loaded_models_baseline keys.\")\n",
    "    else:\n",
    "        for key, model in optimized_models_non_smote.items():\n",
    "            full_variant, clf_name = key.rsplit(\"_\", 1)\n",
    "            print(f\"\\nüîç Explainability for {clf_name} ({full_variant}) [non-SMOTE]\")\n",
    "    \n",
    "            # --- Use optimized W2V test data ---\n",
    "            variant_lookup = \"w2v_optimized_radiology\"\n",
    "            X_sample = X_samples.get(\"w2v_optimized_radiology\")  # use same W2V optimized radiology since embeddings are *_w2v_opt_rad\n",
    "            if X_sample is None:\n",
    "                print(\"‚ö†Ô∏è No test sample available for w2v_radiology ‚Äî skipping.\")\n",
    "                continue\n",
    "    \n",
    "            # --- Safe unwrap for both pipelines and direct estimators ---\n",
    "            if hasattr(model, \"named_steps\"):\n",
    "                clf = model.named_steps.get(\"clf\", model)\n",
    "            else:\n",
    "                clf = model\n",
    "    \n",
    "            # ---------- Skip SVC ----------\n",
    "            if clf_name == \"SVC\":\n",
    "                print(f\"‚ÑπÔ∏è Skipping explainability for {clf_name} (computationally expensive).\")\n",
    "                continue\n",
    "    \n",
    "            # ---------- Logistic Regression ----------\n",
    "            if \"LogisticRegression\" in clf_name:\n",
    "                coef = clf.coef_.ravel()\n",
    "                features = getattr(model.named_steps.get(\"scaler\", None), \"feature_names_in_\", None) \\\n",
    "                           if hasattr(model, \"named_steps\") else X_sample.columns\n",
    "                if features is None:\n",
    "                    features = X_sample.columns\n",
    "    \n",
    "                importance_df = pd.DataFrame({\"Feature\": features, \"Coefficient\": coef})\n",
    "                importance_df[\"AbsValue\"] = importance_df[\"Coefficient\"].abs()\n",
    "                topn = importance_df.sort_values(\"AbsValue\", ascending=False).head(15)\n",
    "    \n",
    "                plt.figure(figsize=(8,6))\n",
    "                plt.barh(topn[\"Feature\"][::-1], topn[\"Coefficient\"][::-1], color=\"steelblue\")\n",
    "                plt.xlabel(\"Coefficient Value\")\n",
    "                plt.title(f\"Top 15 Coefficients ({clf_name}, w2v_optimized_radiology ‚Äî Non-SMOTE)\")\n",
    "                plt.tight_layout()\n",
    "                save_coef = optimized_fig_dir / f\"coefficients_w2v_optimized_radiology_non_smote_{clf_name}.png\"\n",
    "                plt.savefig(save_coef, dpi=300, bbox_inches=\"tight\")\n",
    "                plt.close()\n",
    "                print(f\"üìä Saved coefficient plot ‚Üí {save_coef}\")\n",
    "\n",
    "                # ---------- True SHAP Dependence Plot (avg_urine_output) ----------\n",
    "                try:\n",
    "                    feature_name = \"avg_urineoutput\"\n",
    "                    X_bg = X_sample.sample(n=min(800, len(X_sample)), random_state=42)\n",
    "                \n",
    "                    # SHAP explainability for linear model\n",
    "                    if hasattr(clf, \"predict_proba\"):\n",
    "                        explainer = shap.Explainer(clf.predict_proba, X_bg)\n",
    "                        shap_values = explainer(X_sample)\n",
    "                    elif hasattr(clf, \"decision_function\"):\n",
    "                        explainer = shap.Explainer(clf.decision_function, X_bg)\n",
    "                        shap_values = explainer(X_sample)\n",
    "                    else:\n",
    "                        raise RuntimeError(\"Model has no callable prediction function for SHAP.\")\n",
    "                \n",
    "                    # --- Normalize shape ---\n",
    "                    vals = getattr(shap_values, \"values\", shap_values)\n",
    "                    if isinstance(vals, list):        # handle list of arrays (binary classification)\n",
    "                        vals = vals[1]                # select class 1\n",
    "                    elif isinstance(vals, np.ndarray) and vals.ndim == 3:\n",
    "                        vals = vals[:, :, 1]          # select class 1 slice\n",
    "                    elif not isinstance(vals, np.ndarray):\n",
    "                        vals = np.array(vals)\n",
    "                \n",
    "                    if vals.ndim != 2:\n",
    "                        raise ValueError(f\"Unexpected SHAP output shape: {vals.shape}\")\n",
    "                \n",
    "                    # --- True SHAP dependence plot ---\n",
    "                    shap.dependence_plot(\n",
    "                        feature_name,\n",
    "                        vals,\n",
    "                        X_sample,\n",
    "                        interaction_index=None,\n",
    "                        show=False\n",
    "                    )\n",
    "                    save_dep = optimized_fig_dir / (\n",
    "                        f\"shap_dependence_w2v_optimized_radiology_non_smote_\"\n",
    "                        f\"LogisticRegression_{feature_name}.png\"\n",
    "                    )\n",
    "                    plt.title(\n",
    "                        f\"Dependence: {feature_name} \"\n",
    "                        f\"(LogisticRegression, w2v_optimized_radiology ‚Äî Non-SMOTE)\"\n",
    "                    )\n",
    "                    plt.tight_layout()\n",
    "                    plt.savefig(save_dep, dpi=300, bbox_inches=\"tight\")\n",
    "                    plt.close()\n",
    "                    print(f\"üìà Saved true SHAP dependence plot ‚Üí {save_dep}\")\n",
    "                    mlflow.log_artifact(str(save_dep), artifact_path=\"figures\")\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è SHAP dependence plot failed for LogisticRegression: {e}\")\n",
    "                continue\n",
    "    \n",
    "            # ---------- SHAP Explainability ----------\n",
    "            try:\n",
    "                X_bg = X_sample.sample(n=min(800, len(X_sample)), random_state=42)\n",
    "    \n",
    "                # Prefer TreeExplainer for tree-based models\n",
    "                if hasattr(clf, \"get_booster\") or hasattr(clf, \"feature_importances_\"):\n",
    "                    try:\n",
    "                        explainer = shap.TreeExplainer(clf, X_bg, feature_perturbation=\"interventional\")\n",
    "                        shap_values = explainer(X_sample, check_additivity=False)\n",
    "                    except Exception:\n",
    "                        explainer = shap.Explainer(clf.predict, X_bg)\n",
    "                        shap_values = explainer(X_sample)\n",
    "                else:\n",
    "                    if hasattr(clf, \"predict_proba\"):\n",
    "                        explainer = shap.Explainer(clf.predict_proba, X_bg)\n",
    "                    elif hasattr(clf, \"decision_function\"):\n",
    "                        explainer = shap.Explainer(clf.decision_function, X_bg)\n",
    "                    else:\n",
    "                        print(f\"‚ö†Ô∏è No callable predict_proba or decision_function for {clf_name}, skipping.\")\n",
    "                        continue\n",
    "                    shap_values = explainer(X_sample)\n",
    "    \n",
    "                # ---------- SHAP Summary Plot ----------\n",
    "                shap.summary_plot(shap_values, X_sample, show=False, plot_type=\"bar\", max_display=15)\n",
    "                save_bar = optimized_fig_dir / f\"shap_summary_w2v_optimized_radiology_non_smote_{clf_name}.png\"\n",
    "                plt.title(f\"Top 15 SHAP Features ({clf_name}, w2v_optimized_radiology ‚Äî Non-SMOTE)\")\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(save_bar, dpi=300, bbox_inches=\"tight\")\n",
    "                plt.close()\n",
    "                print(f\"üìä Saved SHAP summary ‚Üí {save_bar}\")\n",
    "                mlflow.log_artifact(str(save_bar), artifact_path=\"figures\")\n",
    "    \n",
    "                # ---------- SHAP Dependence Plot ----------\n",
    "                try:\n",
    "                    if isinstance(clf, (DecisionTreeClassifier, RandomForestClassifier)):\n",
    "                        vals = shap_values.values\n",
    "                        if isinstance(vals, list):\n",
    "                            vals = vals[1] if len(vals) > 1 else vals[0]\n",
    "                        elif vals.ndim == 3:\n",
    "                            vals = vals[:, :, 1]\n",
    "                        else:\n",
    "                            vals = np.array(vals)\n",
    "    \n",
    "                        abs_mean = np.abs(vals).mean(0)\n",
    "                        top_feature = X_sample.columns[abs_mean.argmax()]\n",
    "                        shap.dependence_plot(top_feature, vals, X_sample, show=False)\n",
    "                        save_dep = optimized_fig_dir / f\"shap_dependence_w2v_optimized_radiology_non_smote_{clf_name}_{top_feature}.png\"\n",
    "                        plt.title(f\"Dependence: {top_feature} ({clf_name}, w2v_optimized_radiology ‚Äî Non-SMOTE)\")\n",
    "                        plt.tight_layout()\n",
    "                        plt.savefig(save_dep, dpi=300, bbox_inches=\"tight\")\n",
    "                        plt.close()\n",
    "                        print(f\"üìà Saved dependence plot ‚Üí {save_dep}\")\n",
    "                        mlflow.log_artifact(str(save_dep), artifact_path=\"figures\")\n",
    "                    else:\n",
    "                        vals = getattr(shap_values, \"values\", shap_values)\n",
    "                        if vals is None or np.ndim(vals) != 2:\n",
    "                            raise ValueError(\"Invalid SHAP output shape for dependence plot.\")\n",
    "                        abs_mean = np.abs(vals).mean(0)\n",
    "                        top_feature = X_sample.columns[abs_mean.argmax()]\n",
    "                        shap.dependence_plot(top_feature, vals, X_sample, show=False)\n",
    "                        save_dep = optimized_fig_dir / f\"shap_dependence_w2v_optimized_radiology_non_smote_{clf_name}_{top_feature}.png\"\n",
    "                        plt.title(f\"Dependence: {top_feature} ({clf_name}, w2v_optimized_radiology ‚Äî Non-SMOTE)\")\n",
    "                        plt.tight_layout()\n",
    "                        plt.savefig(save_dep, dpi=300, bbox_inches=\"tight\")\n",
    "                        plt.close()\n",
    "                        print(f\"üìà Saved dependence plot ‚Üí {save_dep}\")\n",
    "                        mlflow.log_artifact(str(save_dep), artifact_path=\"figures\")\n",
    "    \n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Dependence SHAP failed for {clf_name}: {e}\")\n",
    "                    try:\n",
    "                        result = permutation_importance(\n",
    "                            clf, X_sample, y_tests[\"w2v_radiology\"],\n",
    "                            n_repeats=10, random_state=42\n",
    "                        )\n",
    "                        importances = pd.Series(result.importances_mean, index=X_sample.columns)\n",
    "                        top_imp = importances.sort_values(ascending=False).head(15)\n",
    "    \n",
    "                        plt.figure(figsize=(8,6))\n",
    "                        plt.barh(top_imp.index[::-1], top_imp.values[::-1], color=\"darkorange\")\n",
    "                        plt.title(f\"Top 15 Permutation Importances ({clf_name}, w2v_optimized_radiology ‚Äî Non-SMOTE)\")\n",
    "                        plt.xlabel(\"Mean Importance (Œî Accuracy)\")\n",
    "                        plt.tight_layout()\n",
    "                        save_perm = optimized_fig_dir / f\"perm_importance_w2v_optimized_radiology_non_smote_{clf_name}.png\"\n",
    "                        plt.savefig(save_perm, dpi=300, bbox_inches=\"tight\")\n",
    "                        plt.close()\n",
    "                        print(f\"ü™Ñ Fallback: saved permutation importance plot ‚Üí {save_perm}\")\n",
    "                        mlflow.log_artifact(str(save_perm), artifact_path=\"figures\")\n",
    "                    except Exception as e2:\n",
    "                        print(f\"‚ö†Ô∏è Dependence skipped for {clf_name}: {e2}\")\n",
    "    \n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è SHAP failed for {clf_name}: {e}\")\n",
    "    \n",
    "    print(\"üèÅ Completed SHAP and coefficient explainability for all optimized W2V NON-SMOTE models.\")\n",
    "\n",
    "    \n",
    "    # ==================================================\n",
    "    # From 06b 13b Compute SHAP Values and Coefficient Importances (Optimized W2V SMOTE only)\n",
    "    # ==================================================\n",
    "    print(\"\\nüìà Starting SHAP + Coefficient Explainability for optimized W2V SMOTE models\")\n",
    "    \n",
    "    # Directory for all optimized explainability outputs\n",
    "    optimized_fig_dir = resolve_path(\"results/figures/w2v_optimized_radiology_smote/\")\n",
    "    optimized_fig_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    \n",
    "    # Ensure only W2V optimized models are selected\n",
    "    optimized_models = {\n",
    "        k: v for k, v in loaded_models_smote.items()\n",
    "        if \"w2v_optimized_radiology\" in k\n",
    "    }\n",
    "    \n",
    "    if not optimized_models:\n",
    "        print(\"‚ö†Ô∏è No optimized W2V SMOTE models found ‚Äî check loaded_models_smote keys.\")\n",
    "    else:\n",
    "        for key, model in optimized_models.items():\n",
    "            parts = key.split(\"_\")\n",
    "\n",
    "            # Handle all suffix patterns gracefully\n",
    "            if parts[-1] == \"smote\":\n",
    "                clf_name = parts[-2]\n",
    "                full_variant = \"_\".join(parts[:-1])          # drop only the trailing 'smote'\n",
    "            elif parts[-1] == \"baseline\" and \"smote\" in parts:\n",
    "                clf_name = parts[-3]\n",
    "                full_variant = \"_\".join(parts[:-2])          # drop 'smote_baseline'\n",
    "            else:\n",
    "                clf_name = parts[-1]\n",
    "                full_variant = \"_\".join(parts[:-1])\n",
    "            \n",
    "            print(f\"üîç Explainability for {clf_name} ({full_variant}) [SMOTE]\")\n",
    "            \n",
    "            print(f\"\\nüîç Explainability for {clf_name} ({full_variant})\")\n",
    "    \n",
    "            # --- Use only optimized W2V test sample ---\n",
    "            variant_lookup = \"w2v_optimized_radiology\"\n",
    "            X_sample = X_samples.get(\"w2v_optimized_radiology\")  # use W2V radiology test sample as proxy\n",
    "            if X_sample is None:\n",
    "                print(\"‚ö†Ô∏è No test sample available for w2v_radiology ‚Äî skipping.\")\n",
    "                continue\n",
    "    \n",
    "            # --- Safe unwrap for both pipelines and direct estimators ---\n",
    "            if hasattr(model, \"named_steps\"):\n",
    "                clf = model.named_steps.get(\"clf\", model)\n",
    "            else:\n",
    "                clf = model\n",
    "    \n",
    "            # ---------- Skip SVC (computationally heavy) ----------\n",
    "            if clf_name == \"SVC\":\n",
    "                print(f\"‚ÑπÔ∏è Skipping explainability for {clf_name} (computationally expensive).\")\n",
    "                continue\n",
    "    \n",
    "           # ---------- Logistic Regression ----------\n",
    "            if \"LogisticRegression\" in clf_name:\n",
    "                coef = clf.coef_.ravel()\n",
    "                features = getattr(model.named_steps.get(\"scaler\", None), \"feature_names_in_\", None) \\\n",
    "                           if hasattr(model, \"named_steps\") else X_sample.columns\n",
    "                if features is None:\n",
    "                    features = X_sample.columns\n",
    "            \n",
    "                importance_df = pd.DataFrame({\"Feature\": features, \"Coefficient\": coef})\n",
    "                importance_df[\"AbsValue\"] = importance_df[\"Coefficient\"].abs()\n",
    "                topn = importance_df.sort_values(\"AbsValue\", ascending=False).head(15)\n",
    "            \n",
    "                plt.figure(figsize=(8, 6))\n",
    "                plt.barh(topn[\"Feature\"][::-1], topn[\"Coefficient\"][::-1], color=\"steelblue\")\n",
    "                plt.xlabel(\"Coefficient Value\")\n",
    "                plt.title(f\"Top 15 Coefficients ({clf_name}, w2v_optimized_radiology + SMOTE)\")\n",
    "                plt.tight_layout()\n",
    "                save_coef = optimized_fig_dir / f\"coefficients_w2v_optimized_radiology_smote_{clf_name}.png\"\n",
    "                plt.savefig(save_coef, dpi=300, bbox_inches=\"tight\")\n",
    "                plt.close()\n",
    "                print(f\"üìä Saved coefficient plot ‚Üí {save_coef}\")\n",
    "                mlflow.log_artifact(str(save_coef), artifact_path=\"figures\")\n",
    "            \n",
    "                # ---------- True SHAP Dependence Plot (avg_urineoutput) ----------\n",
    "                try:\n",
    "                    feature_name = \"avg_urineoutput\"\n",
    "                    X_bg = X_sample.sample(n=min(800, len(X_sample)), random_state=42)\n",
    "            \n",
    "                    # SHAP explainability for linear model\n",
    "                    if hasattr(clf, \"predict_proba\"):\n",
    "                        explainer = shap.Explainer(clf.predict_proba, X_bg)\n",
    "                        shap_values = explainer(X_sample)\n",
    "                    elif hasattr(clf, \"decision_function\"):\n",
    "                        explainer = shap.Explainer(clf.decision_function, X_bg)\n",
    "                        shap_values = explainer(X_sample)\n",
    "                    else:\n",
    "                        raise RuntimeError(\"Model has no callable prediction function for SHAP.\")\n",
    "            \n",
    "                    # --- Normalize shape ---\n",
    "                    vals = getattr(shap_values, \"values\", shap_values)\n",
    "                    if isinstance(vals, list):          # handle list of arrays (binary classification)\n",
    "                        vals = vals[1]                  # select class 1\n",
    "                    elif isinstance(vals, np.ndarray) and vals.ndim == 3:\n",
    "                        vals = vals[:, :, 1]            # select class 1 slice\n",
    "                    elif not isinstance(vals, np.ndarray):\n",
    "                        vals = np.array(vals)\n",
    "            \n",
    "                    if vals.ndim != 2:\n",
    "                        raise ValueError(f\"Unexpected SHAP output shape: {vals.shape}\")\n",
    "            \n",
    "                    # --- True SHAP dependence plot ---\n",
    "                    shap.dependence_plot(\n",
    "                        feature_name,\n",
    "                        vals,\n",
    "                        X_sample,\n",
    "                        interaction_index=None,\n",
    "                        show=False\n",
    "                    )\n",
    "                    save_dep = optimized_fig_dir / (\n",
    "                        f\"shap_dependence_w2v_optimized_radiology_smote_\"\n",
    "                        f\"LogisticRegression_{feature_name}.png\"\n",
    "                    )\n",
    "                    plt.title(\n",
    "                        f\"Dependence: {feature_name} \"\n",
    "                        f\"(LogisticRegression, w2v_optimized_radiology + SMOTE)\"\n",
    "                    )\n",
    "                    plt.tight_layout()\n",
    "                    plt.savefig(save_dep, dpi=300, bbox_inches=\"tight\")\n",
    "                    plt.close()\n",
    "                    print(f\"üìà Saved true SHAP dependence plot ‚Üí {save_dep}\")\n",
    "                    mlflow.log_artifact(str(save_dep), artifact_path=\"figures\")\n",
    "            \n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è SHAP dependence plot failed for LogisticRegression: {e}\")\n",
    "                continue\n",
    "\n",
    "\n",
    "    \n",
    "            # ---------- SHAP Explainability ----------\n",
    "            try:\n",
    "                X_bg = X_sample.sample(n=min(800, len(X_sample)), random_state=42)\n",
    "    \n",
    "                # Prefer TreeExplainer for tree-based models\n",
    "                if hasattr(clf, \"get_booster\") or hasattr(clf, \"feature_importances_\"):\n",
    "                    try:\n",
    "                        explainer = shap.TreeExplainer(clf, X_bg, feature_perturbation=\"interventional\")\n",
    "                        shap_values = explainer(X_sample, check_additivity=False)\n",
    "                    except Exception:\n",
    "                        explainer = shap.Explainer(clf.predict, X_bg)\n",
    "                        shap_values = explainer(X_sample)\n",
    "                else:\n",
    "                    if hasattr(clf, \"predict_proba\"):\n",
    "                        explainer = shap.Explainer(clf.predict_proba, X_bg)\n",
    "                    elif hasattr(clf, \"decision_function\"):\n",
    "                        explainer = shap.Explainer(clf.decision_function, X_bg)\n",
    "                    else:\n",
    "                        print(f\"‚ö†Ô∏è No callable predict_proba or decision_function for {clf_name}, skipping.\")\n",
    "                        continue\n",
    "                    shap_values = explainer(X_sample)\n",
    "    \n",
    "                # ---------- SHAP Summary Plot ----------\n",
    "                shap.summary_plot(shap_values, X_sample, show=False, plot_type=\"bar\", max_display=15)\n",
    "                save_bar = optimized_fig_dir / f\"shap_summary_w2v_optimized_radiology_smote_{clf_name}.png\"\n",
    "\n",
    "                plt.title(f\"Top 15 SHAP Features ({clf_name}, w2v_optimized_radiology + SMOTE)\")\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(save_bar, dpi=300, bbox_inches=\"tight\")\n",
    "                plt.close()\n",
    "                print(f\"üìä Saved SHAP summary for {clf_name} ‚Üí {save_bar}\")\n",
    "                mlflow.log_artifact(str(save_bar), artifact_path=\"figures\")\n",
    "                \n",
    "                # ---------- SHAP Dependence Plot ----------\n",
    "                try:\n",
    "                    vals = getattr(shap_values, \"values\", shap_values)\n",
    "                    if vals is None or np.ndim(vals) != 2:\n",
    "                        raise ValueError(\"Invalid SHAP output shape for dependence plot.\")\n",
    "                \n",
    "                    abs_mean = np.abs(vals).mean(0)\n",
    "                    top_feature = X_sample.columns[abs_mean.argmax()]\n",
    "                    shap.dependence_plot(top_feature, vals, X_sample, show=False)\n",
    "                    save_dep = optimized_fig_dir / f\"shap_dependence_w2v_optimized_radiology_smote_{clf_name}_{top_feature}.png\"\n",
    "                    plt.title(f\"Dependence: {top_feature} ({clf_name}, w2v_optimized_radiology + SMOTE)\")\n",
    "                    plt.tight_layout()\n",
    "                    plt.savefig(save_dep, dpi=300, bbox_inches=\"tight\")\n",
    "                    plt.close()\n",
    "                    print(f\"üìà Saved dependence plot for {clf_name} ‚Üí {save_dep}\")\n",
    "                    mlflow.log_artifact(str(save_dep), artifact_path=\"figures\")\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Dependence SHAP failed for {clf_name}: {e}\")\n",
    "                    try:\n",
    "                        result = permutation_importance(\n",
    "                            clf, X_sample, y_tests[\"w2v_radiology\"],\n",
    "                            n_repeats=10, random_state=42\n",
    "                        )\n",
    "                        importances = pd.Series(result.importances_mean, index=X_sample.columns)\n",
    "                        top_imp = importances.sort_values(ascending=False).head(15)\n",
    "                \n",
    "                        plt.figure(figsize=(8,6))\n",
    "                        plt.barh(top_imp.index[::-1], top_imp.values[::-1], color=\"darkorange\")\n",
    "                        plt.title(f\"Top 15 Permutation Importances ({clf_name}, w2v_optimized_radiology + SMOTE)\")\n",
    "                        plt.xlabel(\"Mean Importance (Œî Accuracy)\")\n",
    "                        plt.tight_layout()\n",
    "                        save_perm = optimized_fig_dir / f\"perm_importance_w2v_optimized_radiology_smote_{clf_name}.png\"\n",
    "                        plt.savefig(save_perm, dpi=300, bbox_inches=\"tight\")\n",
    "                        plt.close()\n",
    "                        print(f\"ü™Ñ Fallback: saved permutation importance plot for {clf_name} ‚Üí {save_perm}\")\n",
    "                        mlflow.log_artifact(str(save_perm), artifact_path=\"figures\")\n",
    "                    except Exception as e2:\n",
    "                        print(f\"‚ö†Ô∏è Dependence skipped for {clf_name}: {e2}\")\n",
    "\n",
    "    \n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è SHAP failed for {clf_name}: {e}\")\n",
    "    \n",
    "    print(\"üèÅ Completed SHAP and coefficient explainability for all optimized W2V SMOTE models.\")\n",
    "\n",
    "    # ==================================================\n",
    "    # 14‚Äì16 Calibration Analysis & Optimized Model Comparisons\n",
    "    # ==================================================\n",
    "    from sklearn.calibration import calibration_curve\n",
    "    from sklearn.metrics import brier_score_loss\n",
    "    \n",
    "    # --------------------------------------------------\n",
    "    # 14 Calibration Paths\n",
    "    # --------------------------------------------------\n",
    "    calib_dir = resolve_path(\"results/figures/calibration/\")\n",
    "    calib_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"üìÅ Calibration figures will be saved to: {calib_dir}\")\n",
    "    mlflow.log_artifact(str(calib_dir), artifact_path=\"figures\")\n",
    "    \n",
    "    # --------------------------------------------------\n",
    "    # 15a Compute Brier Scores and Calibration Curves\n",
    "    # --------------------------------------------------\n",
    "    records_opt, records_baseline = [], []\n",
    "    \n",
    "    # Only evaluate optimized vs baseline comparisons\n",
    "    target_variants = [\"w2v_optimized_radiology\"]\n",
    "    \n",
    "    for variant in target_variants:\n",
    "        for key, model in loaded_models_baseline.items():\n",
    "            if variant not in key:\n",
    "                continue\n",
    "            full_variant, clf_name = key.rsplit(\"_\", 1)\n",
    "            print(f\"\\nüìè Calibration: {clf_name} ({full_variant})\")\n",
    "    \n",
    "            X_test = X_tests.get(variant)\n",
    "            y_test = y_tests.get(variant)\n",
    "            if X_test is None or y_test is None:\n",
    "                print(f\"‚ö†Ô∏è Missing test data for {variant}\")\n",
    "                continue\n",
    "    \n",
    "            clf = model.named_steps.get(\"clf\", model) if hasattr(model, \"named_steps\") else model\n",
    "            try:\n",
    "                if hasattr(clf, \"predict_proba\"):\n",
    "                    y_proba = clf.predict_proba(X_test)[:, 1]\n",
    "                elif hasattr(clf, \"decision_function\"):\n",
    "                    scores = clf.decision_function(X_test)\n",
    "                    y_proba = (scores - scores.min()) / (scores.max() - scores.min())\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è {clf_name} provides neither predict_proba nor decision_function, skipping.\")\n",
    "                    continue\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è {clf_name} probability computation failed: {e}\")\n",
    "                continue\n",
    "    \n",
    "            brier = brier_score_loss(y_test, y_proba)\n",
    "            prob_true, prob_pred = calibration_curve(y_test, y_proba, n_bins=10, strategy=\"uniform\")\n",
    "    \n",
    "            variant_calib_dir = resolve_path(f\"results/figures/{variant}/calibrations/\")\n",
    "            variant_calib_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "            # Only save and log figures for the optimized variant\n",
    "            if variant == \"w2v_optimized_radiology\":\n",
    "                plt.figure(figsize=(6,6))\n",
    "                plt.plot(prob_pred, prob_true, marker=\"o\", label=f\"{clf_name} ({variant})\")\n",
    "                plt.plot([0,1],[0,1],\"--\",color=\"gray\",label=\"Perfect Calibration\")\n",
    "                plt.xlabel(\"Predicted Probability\")\n",
    "                plt.ylabel(\"Observed Proportion\")\n",
    "                plt.title(f\"Reliability Curve ‚Äî {clf_name} ({variant})\\nBrier Score = {brier:.3f}\")\n",
    "                            # ---------- FIXED LEGEND POSITION ----------\n",
    "                plt.legend(\n",
    "                    loc=\"upper center\",\n",
    "                    bbox_to_anchor=(0.5, -0.20),   # Places legend BELOW x-axis\n",
    "                    frameon=False,\n",
    "                    ncol=1,\n",
    "                    fontsize=10\n",
    "                )\n",
    "                # ------------------------------------------\n",
    "                plt.grid(alpha=0.3)\n",
    "                save_path = variant_calib_dir / f\"calibration_{variant}_{clf_name}.png\"\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "                plt.close()\n",
    "                print(f\"üìä Saved ‚Üí {save_path}\")\n",
    "                mlflow.log_artifact(str(save_path), artifact_path=\"figures\")\n",
    "                print(f\"Saved calibration plot for optimized variant: {clf_name}\")\n",
    "            else:\n",
    "                print(f\"Skipped calibration plot for baseline variant: {clf_name}\")\n",
    "\n",
    "    \n",
    "            records_opt.append({\"Variant\": variant, \"Classifier\": clf_name, \"BrierScore\": brier})\n",
    "    \n",
    "    # Aggregate Brier Scores for summary\n",
    "    if records_opt:\n",
    "        calib_df_opt = pd.DataFrame(records_opt).sort_values(\"BrierScore\")\n",
    "        out_csv = resolve_path(\"results/figures/calibration/calibration_summary_optimized.csv\")\n",
    "        out_csv.parent.mkdir(parents=True, exist_ok=True)\n",
    "        calib_df_opt.to_csv(out_csv, index=False)\n",
    "        print(f\"‚úÖ Calibration summary saved ‚Üí {out_csv}\")\n",
    "        mlflow.log_artifact(str(out_csv), artifact_path=\"summaries\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No calibration metrics computed.\")\n",
    "    \n",
    "    # --------------------------------------------------\n",
    "    # 16a Compare Optimized vs. Baseline Probabilities\n",
    "    # --------------------------------------------------\n",
    "    def compare_predicted_probs(model_dict, reference_dict, clf_name, variant_root, ref_variant):\n",
    "        \"\"\"Compare mean absolute probability differences between two model families.\"\"\"\n",
    "        k_opt = f\"{variant_root}_{clf_name}\"\n",
    "        k_ref = f\"{ref_variant}_baseline_{clf_name}\"\n",
    "    \n",
    "        if k_opt not in model_dict or k_ref not in reference_dict:\n",
    "            print(f\"‚ö†Ô∏è Missing model keys for {clf_name} ({variant_root} vs {ref_variant}).\")\n",
    "            return\n",
    "    \n",
    "        m_opt = model_dict[k_opt]\n",
    "        m_ref = reference_dict[k_ref]\n",
    "        clf_opt = m_opt.named_steps.get(\"clf\", m_opt) if hasattr(m_opt, \"named_steps\") else m_opt\n",
    "        clf_ref = m_ref.named_steps.get(\"clf\", m_ref) if hasattr(m_ref, \"named_steps\") else m_ref\n",
    "    \n",
    "        # ‚úÖ use each model's own test set\n",
    "        X_opt = X_tests[variant_root]\n",
    "        X_ref = X_tests[ref_variant]\n",
    "    \n",
    "        try:\n",
    "            # Generate probabilities\n",
    "            if hasattr(clf_opt, \"predict_proba\") and hasattr(clf_ref, \"predict_proba\"):\n",
    "                p_opt = clf_opt.predict_proba(X_opt)[:, 1]\n",
    "                p_ref = clf_ref.predict_proba(X_ref)[:, 1]\n",
    "            elif hasattr(clf_opt, \"decision_function\") and hasattr(clf_ref, \"decision_function\"):\n",
    "                s_opt, s_ref = clf_opt.decision_function(X_opt), clf_ref.decision_function(X_ref)\n",
    "                p_opt = (s_opt - s_opt.min()) / (s_opt.max() - s_opt.min())\n",
    "                p_ref = (s_ref - s_ref.min()) / (s_ref.max() - s_ref.min())\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è {clf_name} provides neither predict_proba nor decision_function (skipping).\")\n",
    "                return\n",
    "    \n",
    "            # Compare distributions (same patients, matched by index)\n",
    "            # Ensure same order and length by aligning indices\n",
    "            n = min(len(p_opt), len(p_ref))\n",
    "            diff = np.mean(np.abs(p_opt[:n] - p_ref[:n]))\n",
    "    \n",
    "            print(f\"Œî mean(|prob diff|) ‚Äî {clf_name:17s} ({variant_root} vs {ref_variant}): {diff:.6f}\")\n",
    "            mlflow.log_metric(f\"prob_diff_{variant_root}_vs_{ref_variant}_{clf_name}\", diff)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Probability comparison failed for {clf_name} ({variant_root} vs {ref_variant}): {e}\")\n",
    "    \n",
    "    # Run comparisons\n",
    "    for clf_name in classifiers:\n",
    "        compare_predicted_probs(\n",
    "            loaded_models_baseline, loaded_models_baseline,\n",
    "            clf_name, \"w2v_optimized_radiology\", \"w2v_radiology\"\n",
    "        )\n",
    "        compare_predicted_probs(\n",
    "            loaded_models_baseline, loaded_models_baseline,\n",
    "            clf_name, \"w2v_optimized_radiology\", \"original\"\n",
    "        )\n",
    "    \n",
    "    print(\"\\nüèÅ Completed Sections 14‚Äì16: Calibration, Brier Scores, and Optimized Model Comparisons.\")\n",
    "\n",
    "    # ==================================================\n",
    "    # 14‚Äì16b Calibration & Comparison for SMOTE Models (Optimized vs Baseline)\n",
    "    # ==================================================\n",
    "    print(\"\\nüîÅ Starting calibration and probability comparison for SMOTE models\")\n",
    "    \n",
    "    # --------------------------------------------------\n",
    "    # 15b Compute Brier Scores for Optimized and Baseline SMOTE Models\n",
    "    # --------------------------------------------------\n",
    "    records_smote_opt = []\n",
    "    \n",
    "    target_variants_smote = [\"w2v_optimized_radiology\"]\n",
    "    \n",
    "    for variant in target_variants_smote:\n",
    "        for key, model in loaded_models_smote.items():\n",
    "            if variant not in key:\n",
    "                continue\n",
    "            parts = key.split(\"_\")\n",
    "\n",
    "            # Handle all suffix patterns gracefully\n",
    "            if parts[-1] == \"smote\":\n",
    "                clf_name = parts[-2]\n",
    "                full_variant = \"_\".join(parts[:-1])          # drop only the trailing 'smote'\n",
    "            elif parts[-1] == \"baseline\" and \"smote\" in parts:\n",
    "                clf_name = parts[-3]\n",
    "                full_variant = \"_\".join(parts[:-2])          # drop 'smote_baseline'\n",
    "            else:\n",
    "                clf_name = parts[-1]\n",
    "                full_variant = \"_\".join(parts[:-1])\n",
    "            \n",
    "            print(f\"üîç Calibration for {clf_name} ({full_variant}) [SMOTE]\")\n",
    "    \n",
    "            X_test = X_tests.get(variant)\n",
    "            y_test = y_tests.get(variant)\n",
    "            if X_test is None or y_test is None:\n",
    "                print(f\"‚ö†Ô∏è Missing test data for {variant}\")\n",
    "                continue\n",
    "    \n",
    "            clf = model.named_steps.get(\"clf\", model) if hasattr(model, \"named_steps\") else model\n",
    "            try:\n",
    "                if hasattr(clf, \"predict_proba\"):\n",
    "                    y_proba = clf.predict_proba(X_test)[:, 1]\n",
    "                elif hasattr(clf, \"decision_function\"):\n",
    "                    scores = clf.decision_function(X_test)\n",
    "                    y_proba = (scores - scores.min()) / (scores.max() - scores.min())\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è {clf_name} provides neither predict_proba nor decision_function, skipping.\")\n",
    "                    continue\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è {clf_name} probability computation failed: {e}\")\n",
    "                continue\n",
    "    \n",
    "            brier = brier_score_loss(y_test, y_proba)\n",
    "            prob_true, prob_pred = calibration_curve(y_test, y_proba, n_bins=10, strategy=\"uniform\")\n",
    "    \n",
    "            variant_calib_dir = resolve_path(f\"results/figures/{variant}_smote/calibrations/\")\n",
    "            variant_calib_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "            # Only save and log figures for the optimized SMOTE variant\n",
    "            if variant == \"w2v_optimized_radiology\":\n",
    "                plt.figure(figsize=(6,6))\n",
    "                plt.plot(prob_pred, prob_true, marker=\"o\", label=f\"{clf_name} ({variant} + SMOTE)\")\n",
    "                plt.plot([0,1],[0,1],\"--\",color=\"gray\",label=\"Perfect Calibration\")\n",
    "                plt.xlabel(\"Predicted Probability\")\n",
    "                plt.ylabel(\"Observed Proportion\")\n",
    "                plt.title(f\"Reliability Curve ‚Äî {clf_name} ({variant} + SMOTE)\\nBrier Score = {brier:.3f}\")\n",
    "                # ---------- FIXED LEGEND POSITION ----------\n",
    "                plt.legend(\n",
    "                    loc=\"upper center\",\n",
    "                    bbox_to_anchor=(0.5, -0.20),   # Places legend BELOW x-axis\n",
    "                    frameon=False,\n",
    "                    ncol=1,\n",
    "                    fontsize=10\n",
    "                )\n",
    "                # ------------------------------------------\n",
    "                plt.grid(alpha=0.3)\n",
    "                save_path = variant_calib_dir / f\"calibration_{variant}_smote_{clf_name}.png\"\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "                plt.close()\n",
    "                print(f\"üìä Saved ‚Üí {save_path}\")\n",
    "                mlflow.log_artifact(str(save_path), artifact_path=\"figures\")\n",
    "                print(f\"Saved calibration plot for optimized SMOTE variant: {clf_name}\")\n",
    "            else:\n",
    "                print(f\"Skipped calibration plot for baseline SMOTE variant: {clf_name}\")\n",
    "\n",
    "    \n",
    "            records_smote_opt.append({\"Variant\": variant, \"Classifier\": clf_name, \"BrierScore\": brier})\n",
    "    \n",
    "    # Aggregate and log summary\n",
    "    if records_smote_opt:\n",
    "        calib_df_smote_opt = pd.DataFrame(records_smote_opt).sort_values(\"BrierScore\")\n",
    "        out_csv_smote_opt = resolve_path(\"results/figures/calibration/calibration_summary_optimized_smote.csv\")\n",
    "        out_csv_smote_opt.parent.mkdir(parents=True, exist_ok=True)\n",
    "        calib_df_smote_opt.to_csv(out_csv_smote_opt, index=False)\n",
    "        print(f\"‚úÖ SMOTE calibration summary saved ‚Üí {out_csv_smote_opt}\")\n",
    "        mlflow.log_artifact(str(out_csv_smote_opt), artifact_path=\"summaries\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No SMOTE calibration metrics computed.\")\n",
    "    \n",
    "   # --------------------------------------------------\n",
    "    # 16b Compare Optimized SMOTE vs. Baseline SMOTE Probabilities\n",
    "    # --------------------------------------------------\n",
    "    def compare_predicted_probs_smote(model_dict, ref_dict, clf_name, variant_root, ref_variant):\n",
    "        \"\"\"\n",
    "        Compare mean absolute probability differences between two SMOTE-trained model sets.\n",
    "        Each model uses its own feature space to avoid feature name mismatches.\n",
    "        \"\"\"\n",
    "        k_opt = f\"{variant_root}_{clf_name}_smote\"\n",
    "        k_ref = f\"{ref_variant}_baseline_{clf_name}_smote_baseline\"\n",
    "    \n",
    "        # Allow both possible baseline naming patterns\n",
    "        if k_ref not in ref_dict:\n",
    "            k_ref = f\"{ref_variant}_smote_baseline_{clf_name}\"\n",
    "    \n",
    "        if k_opt not in model_dict or k_ref not in ref_dict:\n",
    "            print(f\"‚ö†Ô∏è Missing model keys for {clf_name} ({variant_root} vs {ref_variant}) [SMOTE].\")\n",
    "            return\n",
    "    \n",
    "        m_opt = model_dict[k_opt]\n",
    "        m_ref = ref_dict[k_ref]\n",
    "        clf_opt = m_opt.named_steps.get(\"clf\", m_opt) if hasattr(m_opt, \"named_steps\") else m_opt\n",
    "        clf_ref = m_ref.named_steps.get(\"clf\", m_ref) if hasattr(m_ref, \"named_steps\") else m_ref\n",
    "    \n",
    "        # ‚úÖ Use each model's own matching test set\n",
    "        X_opt = X_tests.get(variant_root)\n",
    "        X_ref = X_tests.get(ref_variant)\n",
    "        if X_opt is None or X_ref is None:\n",
    "            print(f\"‚ö†Ô∏è Missing test data for {variant_root} or {ref_variant} [SMOTE].\")\n",
    "            return\n",
    "    \n",
    "        try:\n",
    "            # Predict probabilities with variant-specific feature sets\n",
    "            if hasattr(clf_opt, \"predict_proba\") and hasattr(clf_ref, \"predict_proba\"):\n",
    "                p_opt = clf_opt.predict_proba(X_opt)[:, 1]\n",
    "                p_ref = clf_ref.predict_proba(X_ref)[:, 1]\n",
    "            elif hasattr(clf_opt, \"decision_function\") and hasattr(clf_ref, \"decision_function\"):\n",
    "                s_opt, s_ref = clf_opt.decision_function(X_opt), clf_ref.decision_function(X_ref)\n",
    "                p_opt = (s_opt - s_opt.min()) / (s_opt.max() - s_opt.min())\n",
    "                p_ref = (s_ref - s_ref.min()) / (s_ref.max() - s_ref.min())\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è {clf_name} provides neither predict_proba nor decision_function (skipping).\")\n",
    "                return\n",
    "    \n",
    "            # Align arrays for consistent length (in case of minor index mismatch)\n",
    "            n = min(len(p_opt), len(p_ref))\n",
    "            diff = np.mean(np.abs(p_opt[:n] - p_ref[:n]))\n",
    "    \n",
    "            print(f\"Œî mean(|prob diff|) [SMOTE] ‚Äî {clf_name:17s} ({variant_root} vs {ref_variant}): {diff:.6f}\")\n",
    "            mlflow.log_metric(f\"prob_diff_SMOTE_{variant_root}_vs_{ref_variant}_{clf_name}\", diff)\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Probability comparison failed for {clf_name} ({variant_root} vs {ref_variant}) [SMOTE]: {e}\")\n",
    "\n",
    "    \n",
    "    # Run optimized SMOTE vs baseline SMOTE comparisons\n",
    "    for clf_name in classifiers:\n",
    "        compare_predicted_probs_smote(\n",
    "            loaded_models_smote, loaded_models_smote,\n",
    "            clf_name, \"w2v_optimized_radiology\", \"w2v_radiology\"\n",
    "        )\n",
    "        compare_predicted_probs_smote(\n",
    "            loaded_models_smote, loaded_models_smote,\n",
    "            clf_name, \"w2v_optimized_radiology\", \"original\"\n",
    "        )\n",
    "\n",
    "    \n",
    "    print(\"\\nüèÅ Completed SMOTE calibration, Brier score, and optimized vs baseline probability comparisons.\")\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    # ==================================================\n",
    "    # Graceful MLflow run completion and summary\n",
    "    # ==================================================\n",
    "    \n",
    "    try:\n",
    "        run_end_time = datetime.now()\n",
    "        mlflow.log_param(\"run_end_time\", run_end_time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "        mlflow.log_param(\"run_status\", \"completed\")\n",
    "    \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"üèÅ Final model evaluation completed and logged to MLflow.\")\n",
    "        print(f\"üìÇ Experiment: {experiment_name}\")\n",
    "        print(f\"üïí Run end time: {run_end_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        print(f\"üì¶ Artifacts logged under: {tracking_dir}\")\n",
    "        print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Final MLflow closing block failed: {e}\")\n",
    "    \n",
    "    finally:\n",
    "        try:\n",
    "            mlflow.end_run()\n",
    "            print(\"‚úÖ MLflow run closed successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è MLflow run closure warning: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830ea3b3-1ab7-4049-87a3-6d0fd8ba6bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# Supplementary SHAP Dependence for Top W2V Feature (non-SMOTE)\n",
    "# ==================================================\n",
    "print(\"\\nüéØ Starting SHAP summaries for top W2V embedding feature across all 6 classifiers\")\n",
    "\n",
    "from pathlib import Path\n",
    "import shap, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression  # ‚úÖ required for isinstance() check\n",
    "\n",
    "# --- Reuse sample and models already loaded earlier ---\n",
    "variant = \"w2v_optimized_radiology\"\n",
    "optimized_fig_dir = Path(resolve_path(\"results/figures/w2v_optimized_radiology/\"))\n",
    "X_sample = X_samples[variant]\n",
    "\n",
    "# --- Find optimized models (non-SMOTE) ---\n",
    "optimized_models = {\n",
    "    k: v for k, v in loaded_models_baseline.items()\n",
    "    if \"w2v_optimized_radiology\" in k\n",
    "}\n",
    "\n",
    "# --- Iterate over classifiers ---\n",
    "for key, model in optimized_models.items():\n",
    "    # --- Skip 'best' model entry if present ---\n",
    "    if \"best\" in key.lower():\n",
    "        print(f\"‚è≠Ô∏è Skipping best model key: {key}\")\n",
    "        continue\n",
    "\n",
    "    clf_name = key.split(\"_\")[-1]\n",
    "    if clf_name in [\"SVC\", \"DecisionTree\"]:  # skip SVC and single trees\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nüîé Generating SHAP dependence for top W2V feature ‚Äî {clf_name}\")\n",
    "\n",
    "    # --- Unwrap model safely ---\n",
    "    clf = model.named_steps.get(\"clf\", model) if hasattr(model, \"named_steps\") else model\n",
    "\n",
    "    # --- Run SHAP on sample ---\n",
    "    X_bg = X_sample.sample(n=min(800, len(X_sample)), random_state=42)\n",
    "    try:\n",
    "        if isinstance(clf, LogisticRegression):\n",
    "            # Linear models: use LinearExplainer for stable coefficients\n",
    "            explainer = shap.LinearExplainer(clf, X_bg, feature_perturbation=\"interventional\")\n",
    "            shap_values = explainer(X_sample)\n",
    "        elif hasattr(clf, \"feature_importances_\") or hasattr(clf, \"get_booster\"):\n",
    "            # Tree-based models (CatBoost, GBM, LGBM, RF, XGB)\n",
    "            explainer = shap.TreeExplainer(clf, X_bg, feature_perturbation=\"interventional\")\n",
    "            shap_values = explainer(X_sample, check_additivity=False)\n",
    "        else:\n",
    "            # Generic fallback\n",
    "            explainer = shap.Explainer(clf.predict_proba, X_bg)\n",
    "            shap_values = explainer(X_sample)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è SHAP explainer failed for {clf_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # --- Normalize SHAP output dimensions ---\n",
    "    vals = getattr(shap_values, \"values\", shap_values)\n",
    "    if isinstance(vals, list):\n",
    "        vals = vals[1] if len(vals) > 1 else vals[0]\n",
    "    if vals.ndim == 3:\n",
    "        vals = vals[:, :, 1]\n",
    "\n",
    "    # --- Identify top W2V feature ---\n",
    "    abs_mean = np.abs(vals).mean(0)\n",
    "    feat_series = pd.Series(abs_mean, index=X_sample.columns)\n",
    "    w2v_feats = feat_series[feat_series.index.str.startswith(\"w2v_opt_rad_\")]\n",
    "    if w2v_feats.empty:\n",
    "        print(f\"‚ö†Ô∏è No W2V features detected for {clf_name}\")\n",
    "        continue\n",
    "    top_w2v_feat = w2v_feats.idxmax()\n",
    "    print(f\"   ‚Üí Top W2V feature: {top_w2v_feat}\")\n",
    "    \n",
    "    # --- Initialize interaction_index and choose correlated feature for color shading ---\n",
    "    interaction_index = None\n",
    "    w2v_cols = [c for c in X_sample.columns if c.startswith(\"w2v_opt_rad_\")]\n",
    "    if len(w2v_cols) > 1:\n",
    "        w2v_df = X_sample[w2v_cols]\n",
    "        corr_with_top = (\n",
    "            w2v_df.corrwith(w2v_df[top_w2v_feat])\n",
    "            .abs()\n",
    "            .sort_values(ascending=False)\n",
    "            .drop(top_w2v_feat, errors=\"ignore\")\n",
    "        )\n",
    "        if not corr_with_top.empty:\n",
    "            interaction_index = corr_with_top.index[0]\n",
    "            print(f\"   ‚Üí Using correlated feature for color: {interaction_index}\")\n",
    "\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    shap.dependence_plot(\n",
    "        top_w2v_feat,\n",
    "        vals,\n",
    "        X_sample,\n",
    "        interaction_index=interaction_index,\n",
    "        show=False\n",
    "    )\n",
    "    plt.title(\n",
    "        f\"Dependence: {top_w2v_feat} \"\n",
    "        f\"({clf_name}, Optimized Multimodal ‚Äì Non-SMOTE)\"\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    save_path = optimized_fig_dir / f\"shap_dependence_topW2V_{clf_name}_{top_w2v_feat}.png\"\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    print(f\"üìà Saved dependence plot ‚Üí {save_path}\")\n",
    "    \n",
    "\n",
    "print(\"\\n‚úÖ Completed SHAP dependence plots for top W2V feature across classifiers.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e002a1-010c-4792-81d6-c5013814ae1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# Supplementary SHAP Dependence for Top W2V Feature (SMOTE)\n",
    "# ==================================================\n",
    "print(\"\\nüéØ Starting SHAP summaries for top W2V embedding feature across all 6 classifiers [SMOTE]\")\n",
    "\n",
    "from pathlib import Path\n",
    "import shap, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression  # ‚úÖ required for isinstance() check\n",
    "\n",
    "# --- Reuse sample and models already loaded earlier ---\n",
    "variant = \"w2v_optimized_radiology\"\n",
    "optimized_fig_dir = Path(resolve_path(\"results/figures/w2v_optimized_radiology_smote/\"))\n",
    "X_sample = X_samples[variant]\n",
    "\n",
    "# --- Find optimized models (SMOTE) ---\n",
    "optimized_models = {\n",
    "    k: v for k, v in loaded_models_smote.items()\n",
    "    if \"w2v_optimized_radiology\" in k\n",
    "}\n",
    "\n",
    "# --- Iterate over classifiers ---\n",
    "for key, model in optimized_models.items():\n",
    "    # --- Skip 'best' model entry if present ---\n",
    "    if \"best\" in key.lower():\n",
    "        print(f\"‚è≠Ô∏è Skipping best model key: {key}\")\n",
    "        continue\n",
    "\n",
    "    clf_name = key.split(\"_\")[-2] if key.endswith(\"_smote\") else key.split(\"_\")[-1]\n",
    "    if clf_name in [\"SVC\", \"DecisionTree\"]:  # skip SVC and single trees\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nüîé Generating SHAP dependence for top W2V feature ‚Äî {clf_name} [SMOTE]\")\n",
    "\n",
    "    # --- Unwrap model safely ---\n",
    "    clf = model.named_steps.get(\"clf\", model) if hasattr(model, \"named_steps\") else model\n",
    "\n",
    "    # --- Run SHAP on sample ---\n",
    "    X_bg = X_sample.sample(n=min(800, len(X_sample)), random_state=42)\n",
    "    try:\n",
    "        if isinstance(clf, LogisticRegression):\n",
    "            # Linear models: use LinearExplainer for stable coefficients\n",
    "            explainer = shap.LinearExplainer(clf, X_bg, feature_perturbation=\"interventional\")\n",
    "            shap_values = explainer(X_sample)\n",
    "        elif hasattr(clf, \"feature_importances_\") or hasattr(clf, \"get_booster\"):\n",
    "            # Tree-based models (CatBoost, GBM, LGBM, RF, XGB)\n",
    "            explainer = shap.TreeExplainer(clf, X_bg, feature_perturbation=\"interventional\")\n",
    "            shap_values = explainer(X_sample, check_additivity=False)\n",
    "        else:\n",
    "            # Generic fallback\n",
    "            explainer = shap.Explainer(clf.predict_proba, X_bg)\n",
    "            shap_values = explainer(X_sample)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è SHAP explainer failed for {clf_name} [SMOTE]: {e}\")\n",
    "        continue\n",
    "\n",
    "    # --- Normalize SHAP output dimensions ---\n",
    "    vals = getattr(shap_values, \"values\", shap_values)\n",
    "    if isinstance(vals, list):\n",
    "        vals = vals[1] if len(vals) > 1 else vals[0]\n",
    "    if vals.ndim == 3:\n",
    "        vals = vals[:, :, 1]\n",
    "\n",
    "    # --- Identify top W2V feature ---\n",
    "    abs_mean = np.abs(vals).mean(0)\n",
    "    feat_series = pd.Series(abs_mean, index=X_sample.columns)\n",
    "    w2v_feats = feat_series[feat_series.index.str.startswith(\"w2v_opt_rad_\")]\n",
    "    if w2v_feats.empty:\n",
    "        print(f\"‚ö†Ô∏è No W2V features detected for {clf_name} [SMOTE]\")\n",
    "        continue\n",
    "    top_w2v_feat = w2v_feats.idxmax()\n",
    "    print(f\"   ‚Üí Top W2V feature: {top_w2v_feat}\")\n",
    "\n",
    "    # --- Initialize interaction_index and choose correlated feature for color shading ---\n",
    "    interaction_index = None\n",
    "    w2v_cols = [c for c in X_sample.columns if c.startswith(\"w2v_opt_rad_\")]\n",
    "    if len(w2v_cols) > 1:\n",
    "        w2v_df = X_sample[w2v_cols]\n",
    "        corr_with_top = (\n",
    "            w2v_df.corrwith(w2v_df[top_w2v_feat])\n",
    "            .abs()\n",
    "            .sort_values(ascending=False)\n",
    "            .drop(top_w2v_feat, errors=\"ignore\")\n",
    "        )\n",
    "        if not corr_with_top.empty:\n",
    "            interaction_index = corr_with_top.index[0]\n",
    "            print(f\"   ‚Üí Using correlated feature for color: {interaction_index}\")\n",
    "\n",
    "    # --- Dependence plot ---\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    shap.dependence_plot(\n",
    "        top_w2v_feat,\n",
    "        vals,\n",
    "        X_sample,\n",
    "        interaction_index=interaction_index,\n",
    "        show=False\n",
    "    )\n",
    "    plt.title(\n",
    "        f\"Dependence: {top_w2v_feat} \"\n",
    "        f\"({clf_name}, Optimized Multimodal ‚Äì SMOTE)\"\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "\n",
    "    save_path = optimized_fig_dir / f\"shap_dependence_topW2V_{clf_name}_{top_w2v_feat}.png\"\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    print(f\"üìà Saved dependence plot [SMOTE] ‚Üí {save_path}\")\n",
    "\n",
    "print(\"\\n‚úÖ Completed SHAP dependence plots for top W2V feature across classifiers [SMOTE].\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
