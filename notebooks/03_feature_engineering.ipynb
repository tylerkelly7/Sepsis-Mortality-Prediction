{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0d774a4",
   "metadata": {},
   "source": [
    "# 03 - Feature Engineering\n",
    "\n",
    "## üìå Purpose\n",
    "\n",
    "This notebook generates baseline feature datasets for the thesis pipeline:\n",
    "- **Original structured features** (scaled).\n",
    "- **Word2Vec embeddings** (Radiology, Discharge, Combined).\n",
    "- **Merged datasets** (structured + scaled embeddings).\n",
    "\n",
    "It performs feature engineering with Word2Vec embeddings:\n",
    "- Train/load Word2Vec models on Radiology, Discharge, and Combined notes\n",
    "- Generate subject-level averaged embeddings\n",
    "- Merge embeddings with structured features\n",
    "- Standard scale embeddings\n",
    "\n",
    "All final outputs are saved into `data/processed/` for downstream modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab56da7",
   "metadata": {},
   "source": [
    "\n",
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37f15a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.data_prep import split_data\n",
    "from src.features import (\n",
    "    scale_features,\n",
    "    train_word2vec,\n",
    "    get_w2v_params,\n",
    "    load_word2vec,\n",
    "    apply_embeddings_to_subjects,\n",
    "    scale_w2v_embeddings,\n",
    "    merge_embeddings_with_features,\n",
    "    save_feature_dataset,\n",
    "    validate_saved_datasets\n",
    ")\n",
    "from src.utils import resolve_path\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb67180",
   "metadata": {},
   "source": [
    "## 1. Load NLP-ready dataset\n",
    "\n",
    "We start from `nlp_ready_df`, generated in **02_data_preprocessing.ipynb**.  \n",
    "\n",
    "This step loads the preprocessed dataset containing both\n",
    "structured EHR variables and the concatenated note text columns for\n",
    "radiology, discharge summaries, and combined notes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c933182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded NLP-ready dataset: (5208, 51)\n",
      "Columns: ['subject_id', 'hospital_expire_flag', 'max_age', 'los_icu', 'first_hosp_stay', 'suspected_infection', 'sofa_score', 'sepsis3', 'avg_urineoutput', 'glucose_min'] ...\n"
     ]
    }
   ],
   "source": [
    "nlp_ready_path = resolve_path(\"data/interim/data_nlp_ready.csv\")\n",
    "nlp_ready_df = pd.read_csv(nlp_ready_path)\n",
    "\n",
    "print(f\"‚úÖ Loaded NLP-ready dataset: {nlp_ready_df.shape}\")\n",
    "print(f\"Columns: {nlp_ready_df.columns.tolist()[:10]} ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a15496",
   "metadata": {},
   "source": [
    "## 2. Drop note text columns for structured modeling\n",
    "\n",
    "Drop the raw text columns (`Radiology_notes`, `Discharge_summary_notes`, and `combined_notes`)\n",
    "to isolate purely structured numeric and categorical features.\n",
    "These form the base input for the tabular (non-NLP) models.\n",
    "\n",
    "Then drop additional columns that lead to target leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58e41b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Structured features: (5208, 44), Target: (5208,)\n"
     ]
    }
   ],
   "source": [
    "# Drop note text columns\n",
    "original_df = nlp_ready_df.drop(\n",
    "    columns=[\"Radiology_notes\", \"Discharge_summary_notes\", \"combined_notes\"]\n",
    ")\n",
    "\n",
    "X_original = original_df.drop(columns=[\n",
    "    'hospital_expire_flag',\n",
    "    'first_hosp_stay',\n",
    "    'suspected_infection',\n",
    "    'sepsis3'])\n",
    "y_original = original_df[\"hospital_expire_flag\"]\n",
    "\n",
    "\n",
    "print(f\"‚úÖ Structured features: {X_original.shape}, Target: {y_original.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf0983f",
   "metadata": {},
   "source": [
    "## 3. Train/Test Split Structured features\n",
    "\n",
    "Perform a single consistent train/test split that defines all downstream\n",
    "processing for both structured and text-based feature sets.\n",
    "The same `subject_id` partitions will be reused for all data modalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca3dc009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (4166, 44), Test: (1042, 44)\n"
     ]
    }
   ],
   "source": [
    "X_train_orig, X_test_orig, y_train_orig, y_test_orig = split_data(X_original, y_original, test_size=0.2, random_state=42)\n",
    "print(f\"Train: {X_train_orig.shape}, Test: {X_test_orig.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7784b5ad",
   "metadata": {},
   "source": [
    "## 4. Scale Structured Features\n",
    "\n",
    "Fit a `StandardScaler` on the training structured features and transform both train and test sets.\n",
    "Scaling is performed before merging with embeddings to maintain consistent numeric distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27c1e6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Scaled original features prepared (not saved ‚Äî handled downstream)\n"
     ]
    }
   ],
   "source": [
    "X_train_orig_scaled, X_test_orig_scaled, y_train_orig, y_test_orig = scale_features(\n",
    "    X_train_orig, X_test_orig, y_train_orig, y_test_orig, prefix=\"original\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890cc1d9",
   "metadata": {},
   "source": [
    "## 5. Train or load Baseline Word2Vec Models\n",
    "\n",
    "Train (or load if already available) three baseline Word2Vec models‚Äî\n",
    "one each for Radiology, Discharge, and Combined notes.\n",
    "These models are stored under `embedding_cache/w2v/baseline/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "864d9da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Word2Vec model (baseline) trained and saved to C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\embedding_cache\\w2v\\baseline\\baseline\\w2v_radiology.model\n",
      "‚úÖ Trained & saved radiology Word2Vec model to C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\embedding_cache\\w2v\\baseline\\w2v_radiology.model\n",
      "‚úÖ Word2Vec model (baseline) trained and saved to C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\embedding_cache\\w2v\\baseline\\baseline\\w2v_discharge.model\n",
      "‚úÖ Trained & saved discharge Word2Vec model to C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\embedding_cache\\w2v\\baseline\\w2v_discharge.model\n",
      "‚úÖ Word2Vec model (baseline) trained and saved to C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\embedding_cache\\w2v\\baseline\\baseline\\w2v_combined.model\n",
      "‚úÖ Trained & saved combined Word2Vec model to C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\embedding_cache\\w2v\\baseline\\w2v_combined.model\n",
      "‚úÖ All Word2Vec models ready.\n"
     ]
    }
   ],
   "source": [
    "# Relative paths (pass these to load/train; helpers will resolve)\n",
    "paths = {\n",
    "    \"radiology\": {\n",
    "        \"corpus\": \"data/interim/w2v_interim/w2v_Radiology_notes.txt\",\n",
    "        \"model\":  \"embedding_cache/w2v/baseline/w2v_radiology.model\",\n",
    "    },\n",
    "    \"discharge\": {\n",
    "        \"corpus\": \"data/interim/w2v_interim/w2v_Discharge_notes.txt\",\n",
    "        \"model\":  \"embedding_cache/w2v/baseline/w2v_discharge.model\",\n",
    "    },\n",
    "    \"combined\": {\n",
    "        \"corpus\": \"data/interim/w2v_interim/w2v_combined_notes.txt\",\n",
    "        \"model\":  \"embedding_cache/w2v/baseline/w2v_combined.model\",\n",
    "    },\n",
    "}\n",
    "\n",
    "models = {}\n",
    "for note_type, p in paths.items():\n",
    "    params = get_w2v_params(note_type)\n",
    "    model_abs_path = resolve_path(p[\"model\"])  # only for existence check\n",
    "\n",
    "    if os.path.exists(resolve_path(p[\"model\"])):\n",
    "        models[note_type] = load_word2vec(p[\"model\"])  # ‚úÖ auto-detects baseline if present\n",
    "        print(f\"‚úÖ Loaded {note_type} Word2Vec model.\")\n",
    "    else:\n",
    "        models[note_type] = train_word2vec(\n",
    "            corpus_path=p[\"corpus\"],\n",
    "            model_out=p[\"model\"],\n",
    "            baseline=True,\n",
    "            **params\n",
    "        )\n",
    "        print(f\"‚úÖ Trained & saved {note_type} Word2Vec model to {resolve_path(p['model'])}\")\n",
    "\n",
    "print(\"‚úÖ All Word2Vec models ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e348c48",
   "metadata": {},
   "source": [
    "## 6. Generate Subject-Level Embeddings per Note Type\n",
    "\n",
    "Using the train/test subject IDs from Step 3,\n",
    "generate averaged document embeddings for each subject\n",
    "across all three note types (`Radiology_notes`, `Discharge_summary_notes`, `combined_notes`).\n",
    "Each embedding set will be created separately with its respective model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a35cb5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Radiology embeddings: (4166, 101)\n",
      "‚úÖ Discharge embeddings: (4166, 101)\n",
      "‚úÖ Combined embeddings:  (4166, 101)\n"
     ]
    }
   ],
   "source": [
    "train_ids = set(X_train_orig[\"subject_id\"])\n",
    "test_ids  = set(X_test_orig[\"subject_id\"])\n",
    "\n",
    "# Align note text subsets to train/test subjects\n",
    "train_notes = nlp_ready_df.loc[nlp_ready_df[\"subject_id\"].isin(train_ids)].copy()\n",
    "test_notes  = nlp_ready_df.loc[nlp_ready_df[\"subject_id\"].isin(test_ids)].copy()\n",
    "\n",
    "# Generate averaged embeddings for each model\n",
    "\n",
    "# radiology\n",
    "w2v_train_rad = apply_embeddings_to_subjects(train_notes, \"Radiology_notes\", models[\"radiology\"], prefix=\"w2v_rad_\")\n",
    "w2v_test_rad  = apply_embeddings_to_subjects(test_notes,  \"Radiology_notes\", models[\"radiology\"], prefix=\"w2v_rad_\")\n",
    "# discharge\n",
    "w2v_train_dis = apply_embeddings_to_subjects(train_notes, \"Discharge_summary_notes\", models[\"discharge\"], prefix=\"w2v_dis_\")\n",
    "w2v_test_dis  = apply_embeddings_to_subjects(test_notes,  \"Discharge_summary_notes\", models[\"discharge\"], prefix=\"w2v_dis_\")\n",
    "# combined\n",
    "w2v_train_comb = apply_embeddings_to_subjects(train_notes, \"combined_notes\", models[\"combined\"], prefix=\"w2v_comb_\")\n",
    "w2v_test_comb  = apply_embeddings_to_subjects(test_notes,  \"combined_notes\", models[\"combined\"], prefix=\"w2v_comb_\")\n",
    "\n",
    "print(f\"‚úÖ Radiology embeddings: {w2v_train_rad.shape}\")\n",
    "print(f\"‚úÖ Discharge embeddings: {w2v_train_dis.shape}\")\n",
    "print(f\"‚úÖ Combined embeddings:  {w2v_train_comb.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2b8278",
   "metadata": {},
   "source": [
    "## 7. Scale Embeddings\n",
    "\n",
    "Fit a `StandardScaler` on the training embeddings for each note type\n",
    "and apply the transformation to the test embeddings.\n",
    "This ensures all embedding features have zero mean and unit variance\n",
    "without introducing data leakage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4b7a6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Scaled w2v_rad embeddings saved to C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\embedding_cache\\w2v\\baseline\\w2v_rad (embeddings only, not merged)\n",
      "‚úÖ Scaled w2v_dis embeddings saved to C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\embedding_cache\\w2v\\baseline\\w2v_dis (embeddings only, not merged)\n",
      "‚úÖ Scaled w2v_comb embeddings saved to C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\embedding_cache\\w2v\\baseline\\w2v_comb (embeddings only, not merged)\n",
      "‚úÖ Embeddings scaled\n"
     ]
    }
   ],
   "source": [
    "w2v_train_rad_scaled, w2v_test_rad_scaled = scale_w2v_embeddings(w2v_train_rad, w2v_test_rad, prefix=\"w2v_rad\")\n",
    "w2v_train_dis_scaled, w2v_test_dis_scaled = scale_w2v_embeddings(w2v_train_dis, w2v_test_dis, prefix=\"w2v_dis\")\n",
    "w2v_train_comb_scaled, w2v_test_comb_scaled = scale_w2v_embeddings(w2v_train_comb, w2v_test_comb, prefix=\"w2v_comb\")\n",
    "\n",
    "print(\"‚úÖ Embeddings scaled\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a64c54",
   "metadata": {},
   "source": [
    "## 8. Merge Structured Features + Embeddings\n",
    "\n",
    "Merge the scaled structured features with each set of scaled Word2Vec embeddings.\n",
    "This produces final merged datasets for radiology, discharge, and combined feature spaces.\n",
    "Each merged train/test pair is saved under `data/processed/{variant}/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f43020c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Merged w2v_rad train/test sets saved under C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\data\\processed\\w2v_rad\n",
      "‚úÖ Merged w2v_dis train/test sets saved under C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\data\\processed\\w2v_dis\n",
      "‚úÖ Merged w2v_comb train/test sets saved under C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\data\\processed\\w2v_comb\n",
      "‚úÖ Original + embeddings data merged\n"
     ]
    }
   ],
   "source": [
    "X_train_w2v_rad_scaled, X_test_w2v_rad_scaled = merge_embeddings_with_features(\n",
    "    X_train_orig_scaled, X_test_orig_scaled, w2v_train_rad_scaled, w2v_test_rad_scaled, prefix=\"w2v_rad\"\n",
    ")\n",
    "\n",
    "X_train_w2v_dis_scaled, X_test_w2v_dis_scaled = merge_embeddings_with_features(\n",
    "    X_train_orig_scaled, X_test_orig_scaled, w2v_train_dis_scaled, w2v_test_dis_scaled, prefix=\"w2v_dis\"\n",
    ")\n",
    "\n",
    "X_train_w2v_comb_scaled, X_test_w2v_comb_scaled = merge_embeddings_with_features(\n",
    "    X_train_orig_scaled, X_test_orig_scaled, w2v_train_comb_scaled, w2v_test_comb_scaled, prefix=\"w2v_comb\"\n",
    ")\n",
    "print(\"‚úÖ Original + embeddings data merged\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72fad3f-635f-4027-b7eb-bc970a4c4958",
   "metadata": {},
   "source": [
    "## 9. Remove Subject_ID from Feature Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1667026b-0a34-4fdd-893d-28c44779483b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Removed subject_id from original xtrain\n",
      "‚úÖ Removed subject_id from original xtest\n",
      "‚úÖ Removed subject_id from w2v_radiology xtrain\n",
      "‚úÖ Removed subject_id from w2v_radiology xtest\n",
      "‚úÖ Removed subject_id from w2v_discharge xtrain\n",
      "‚úÖ Removed subject_id from w2v_discharge xtest\n",
      "‚úÖ Removed subject_id from w2v_combined xtrain\n",
      "‚úÖ Removed subject_id from w2v_combined xtest\n"
     ]
    }
   ],
   "source": [
    "# Define all dataset variants\n",
    "variant_scaled_sets = {\n",
    "    \"original\": (X_train_orig_scaled, X_test_orig_scaled),\n",
    "    \"w2v_radiology\": (X_train_w2v_rad_scaled, X_test_w2v_rad_scaled),\n",
    "    \"w2v_discharge\": (X_train_w2v_dis_scaled, X_test_w2v_dis_scaled),\n",
    "    \"w2v_combined\": (X_train_w2v_comb_scaled, X_test_w2v_comb_scaled)\n",
    "}\n",
    "\n",
    "for variant, (xtrain, xtest) in variant_scaled_sets.items():\n",
    "    for df_name, df in {\"xtrain\": xtrain, \"xtest\": xtest}.items():\n",
    "        if \"subject_id\" in df.columns:\n",
    "            df.drop(columns=[\"subject_id\"], inplace=True)\n",
    "            print(f\"‚úÖ Removed subject_id from {variant} {df_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d2dafd",
   "metadata": {},
   "source": [
    "## 10. Save All Processed Datasets\n",
    "\n",
    "All scaled and merged datasets (structured‚Äêonly and Word2Vec variants) are saved\n",
    "to their respective folders under `data/processed/{variant}/`.  \n",
    "\n",
    "Each folder contains the four core files:\n",
    "\n",
    "- `data_{variant}_xtrain.csv`\n",
    "- `data_{variant}_xtest.csv`\n",
    "- `data_{variant}_ytrain.csv`\n",
    "- `data_{variant}_ytest.csv`\n",
    "\n",
    "This centralized save step ensures consistent versioned outputs across all feature modalities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a843dad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Verified: no subject_id columns remain.\n",
      "‚úÖ Saved feature dataset ‚Üí C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\data\\processed\\original\\data_original_xtrain.csv\n",
      "‚úÖ Saved feature dataset ‚Üí C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\data\\processed\\original\\data_original_xtest.csv\n",
      "‚úÖ Saved feature dataset ‚Üí C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\data\\processed\\original\\data_original_ytrain.csv\n",
      "‚úÖ Saved feature dataset ‚Üí C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\data\\processed\\original\\data_original_ytest.csv\n",
      "‚úÖ Saved feature dataset ‚Üí C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\data\\processed\\w2v_radiology\\data_w2v_radiology_xtrain.csv\n",
      "‚úÖ Saved feature dataset ‚Üí C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\data\\processed\\w2v_radiology\\data_w2v_radiology_xtest.csv\n",
      "‚úÖ Saved feature dataset ‚Üí C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\data\\processed\\w2v_radiology\\data_w2v_radiology_ytrain.csv\n",
      "‚úÖ Saved feature dataset ‚Üí C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\data\\processed\\w2v_radiology\\data_w2v_radiology_ytest.csv\n",
      "‚úÖ Saved feature dataset ‚Üí C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\data\\processed\\w2v_discharge\\data_w2v_discharge_xtrain.csv\n",
      "‚úÖ Saved feature dataset ‚Üí C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\data\\processed\\w2v_discharge\\data_w2v_discharge_xtest.csv\n",
      "‚úÖ Saved feature dataset ‚Üí C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\data\\processed\\w2v_discharge\\data_w2v_discharge_ytrain.csv\n",
      "‚úÖ Saved feature dataset ‚Üí C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\data\\processed\\w2v_discharge\\data_w2v_discharge_ytest.csv\n",
      "‚úÖ Saved feature dataset ‚Üí C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\data\\processed\\w2v_combined\\data_w2v_combined_xtrain.csv\n",
      "‚úÖ Saved feature dataset ‚Üí C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\data\\processed\\w2v_combined\\data_w2v_combined_xtest.csv\n",
      "‚úÖ Saved feature dataset ‚Üí C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\data\\processed\\w2v_combined\\data_w2v_combined_ytrain.csv\n",
      "‚úÖ Saved feature dataset ‚Üí C:\\Users\\tyler\\OneDrive - University of Pittsburgh\\BIOST 2021 Thesis\\Masters-Thesis\\data\\processed\\w2v_combined\\data_w2v_combined_ytest.csv\n",
      "‚úÖ All scaled structured and merged datasets successfully saved.\n"
     ]
    }
   ],
   "source": [
    "# dictionary of datasets: prefix ‚Üí (X_train, X_test)\n",
    "\n",
    "datasets_to_save = {\n",
    "    \"original\": (X_train_orig_scaled, X_test_orig_scaled),\n",
    "    \"w2v_radiology\": (X_train_w2v_rad_scaled, X_test_w2v_rad_scaled),\n",
    "    \"w2v_discharge\": (X_train_w2v_dis_scaled, X_test_w2v_dis_scaled),\n",
    "    \"w2v_combined\": (X_train_w2v_comb_scaled, X_test_w2v_comb_scaled)\n",
    "}\n",
    "\n",
    "for name, (Xtr, Xte) in datasets_to_save.items():\n",
    "    assert \"subject_id\" not in Xtr.columns\n",
    "    assert \"subject_id\" not in Xte.columns\n",
    "print(\"‚úÖ Verified: no subject_id columns remain.\")\n",
    "\n",
    "# corresponding y values (shared across all variants)\n",
    "if isinstance(y_train_orig, pd.Series):\n",
    "    y_train_orig = y_train_orig.to_frame()\n",
    "if isinstance(y_test_orig, pd.Series):\n",
    "    y_test_orig = y_test_orig.to_frame()\n",
    "\n",
    "\n",
    "for prefix, (Xtr, Xte) in datasets_to_save.items():\n",
    "    base_dir = f\"data/processed/{prefix}\"\n",
    "    # ensure directory exists\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "    # save X_train / X_test\n",
    "    save_feature_dataset(Xtr, f\"data_{prefix}_xtrain.csv\", base_dir=base_dir)\n",
    "    save_feature_dataset(Xte, f\"data_{prefix}_xtest.csv\",  base_dir=base_dir)\n",
    "\n",
    "    # save y_train / y_test once per variant for clarity\n",
    "    save_feature_dataset(y_train_orig, f\"data_{prefix}_ytrain.csv\", base_dir=base_dir)\n",
    "    save_feature_dataset(y_test_orig,  f\"data_{prefix}_ytest.csv\",  base_dir=base_dir)\n",
    "\n",
    "print(\"‚úÖ All scaled structured and merged datasets successfully saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e314fb97",
   "metadata": {},
   "source": [
    "## 11. Validate all saved dataset outputs\n",
    "\n",
    "This step calls `validate_saved_datasets()`\n",
    "(from `src/features.py`) to check that all processed datasets\n",
    "exist, have valid shapes, and (optionally) preserve `subject_id`\n",
    "alignment between features and labels.\n",
    "\n",
    "A summary table is displayed below; if all entries show `Exists=True`,\n",
    "the preprocessing pipeline is verified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8458368e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variant</th>\n",
       "      <th>Split</th>\n",
       "      <th>File</th>\n",
       "      <th>Exists</th>\n",
       "      <th>Rows</th>\n",
       "      <th>Columns</th>\n",
       "      <th>Aligned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>original</td>\n",
       "      <td>X_train</td>\n",
       "      <td>data_original_xtrain.csv</td>\n",
       "      <td>True</td>\n",
       "      <td>4166</td>\n",
       "      <td>43</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>original</td>\n",
       "      <td>X_test</td>\n",
       "      <td>data_original_xtest.csv</td>\n",
       "      <td>True</td>\n",
       "      <td>1042</td>\n",
       "      <td>43</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>original</td>\n",
       "      <td>y_train</td>\n",
       "      <td>data_original_ytrain.csv</td>\n",
       "      <td>True</td>\n",
       "      <td>4166</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>original</td>\n",
       "      <td>y_test</td>\n",
       "      <td>data_original_ytest.csv</td>\n",
       "      <td>True</td>\n",
       "      <td>1042</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>w2v_radiology</td>\n",
       "      <td>X_train</td>\n",
       "      <td>data_w2v_radiology_xtrain.csv</td>\n",
       "      <td>True</td>\n",
       "      <td>4166</td>\n",
       "      <td>143</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>w2v_radiology</td>\n",
       "      <td>X_test</td>\n",
       "      <td>data_w2v_radiology_xtest.csv</td>\n",
       "      <td>True</td>\n",
       "      <td>1042</td>\n",
       "      <td>143</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>w2v_radiology</td>\n",
       "      <td>y_train</td>\n",
       "      <td>data_w2v_radiology_ytrain.csv</td>\n",
       "      <td>True</td>\n",
       "      <td>4166</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>w2v_radiology</td>\n",
       "      <td>y_test</td>\n",
       "      <td>data_w2v_radiology_ytest.csv</td>\n",
       "      <td>True</td>\n",
       "      <td>1042</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>w2v_discharge</td>\n",
       "      <td>X_train</td>\n",
       "      <td>data_w2v_discharge_xtrain.csv</td>\n",
       "      <td>True</td>\n",
       "      <td>4166</td>\n",
       "      <td>143</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>w2v_discharge</td>\n",
       "      <td>X_test</td>\n",
       "      <td>data_w2v_discharge_xtest.csv</td>\n",
       "      <td>True</td>\n",
       "      <td>1042</td>\n",
       "      <td>143</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>w2v_discharge</td>\n",
       "      <td>y_train</td>\n",
       "      <td>data_w2v_discharge_ytrain.csv</td>\n",
       "      <td>True</td>\n",
       "      <td>4166</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>w2v_discharge</td>\n",
       "      <td>y_test</td>\n",
       "      <td>data_w2v_discharge_ytest.csv</td>\n",
       "      <td>True</td>\n",
       "      <td>1042</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>w2v_combined</td>\n",
       "      <td>X_train</td>\n",
       "      <td>data_w2v_combined_xtrain.csv</td>\n",
       "      <td>True</td>\n",
       "      <td>4166</td>\n",
       "      <td>143</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>w2v_combined</td>\n",
       "      <td>X_test</td>\n",
       "      <td>data_w2v_combined_xtest.csv</td>\n",
       "      <td>True</td>\n",
       "      <td>1042</td>\n",
       "      <td>143</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>w2v_combined</td>\n",
       "      <td>y_train</td>\n",
       "      <td>data_w2v_combined_ytrain.csv</td>\n",
       "      <td>True</td>\n",
       "      <td>4166</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>w2v_combined</td>\n",
       "      <td>y_test</td>\n",
       "      <td>data_w2v_combined_ytest.csv</td>\n",
       "      <td>True</td>\n",
       "      <td>1042</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Variant    Split                           File  Exists  Rows  \\\n",
       "0        original  X_train       data_original_xtrain.csv    True  4166   \n",
       "1        original   X_test        data_original_xtest.csv    True  1042   \n",
       "2        original  y_train       data_original_ytrain.csv    True  4166   \n",
       "3        original   y_test        data_original_ytest.csv    True  1042   \n",
       "4   w2v_radiology  X_train  data_w2v_radiology_xtrain.csv    True  4166   \n",
       "5   w2v_radiology   X_test   data_w2v_radiology_xtest.csv    True  1042   \n",
       "6   w2v_radiology  y_train  data_w2v_radiology_ytrain.csv    True  4166   \n",
       "7   w2v_radiology   y_test   data_w2v_radiology_ytest.csv    True  1042   \n",
       "8   w2v_discharge  X_train  data_w2v_discharge_xtrain.csv    True  4166   \n",
       "9   w2v_discharge   X_test   data_w2v_discharge_xtest.csv    True  1042   \n",
       "10  w2v_discharge  y_train  data_w2v_discharge_ytrain.csv    True  4166   \n",
       "11  w2v_discharge   y_test   data_w2v_discharge_ytest.csv    True  1042   \n",
       "12   w2v_combined  X_train   data_w2v_combined_xtrain.csv    True  4166   \n",
       "13   w2v_combined   X_test    data_w2v_combined_xtest.csv    True  1042   \n",
       "14   w2v_combined  y_train   data_w2v_combined_ytrain.csv    True  4166   \n",
       "15   w2v_combined   y_test    data_w2v_combined_ytest.csv    True  1042   \n",
       "\n",
       "    Columns Aligned  \n",
       "0        43     n/a  \n",
       "1        43     n/a  \n",
       "2         1     NaN  \n",
       "3         1     NaN  \n",
       "4       143     n/a  \n",
       "5       143     n/a  \n",
       "6         1     NaN  \n",
       "7         1     NaN  \n",
       "8       143     n/a  \n",
       "9       143     n/a  \n",
       "10        1     NaN  \n",
       "11        1     NaN  \n",
       "12      143     n/a  \n",
       "13      143     n/a  \n",
       "14        1     NaN  \n",
       "15        1     NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ All processed datasets found and validated.\n"
     ]
    }
   ],
   "source": [
    "output_summary = validate_saved_datasets(check_alignment=True)\n",
    "display(output_summary)\n",
    "\n",
    "if not output_summary[\"Exists\"].all():\n",
    "    missing = output_summary.loc[~output_summary[\"Exists\"], [\"Variant\", \"Split\", \"File\"]]\n",
    "    print(\"\\n‚ö†Ô∏è Missing or invalid files:\")\n",
    "    display(missing)\n",
    "else:\n",
    "    print(\"\\n‚úÖ All processed datasets found and validated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85e44a7",
   "metadata": {},
   "source": [
    "## 12: Next Steps\n",
    "- Proceed to `04_model_training.ipynb` for baseline and tuned models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
